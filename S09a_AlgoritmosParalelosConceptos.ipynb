{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b06738",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Estructura de Datos y Algoritmos II</h1>\n",
    "<h1 align=\"center\">Algoritmos Paralelos - Conceptos</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32776e",
   "metadata": {},
   "source": [
    "*** \n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvar52@eafit.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/S09a_AlgoritmosParalelosConceptos.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5d6c30",
   "metadata": {},
   "source": [
    "# Aviso Legal sobre estas Notas de Clase\n",
    "\n",
    "Las presentes notas de clase han sido elaboradas con fines educativos y como material de apoyo para el aprendizaje y comprensión de la computación paralela. Estas notas están basadas en información y contenidos derivados del tutorial *[\"Introduction to Parallel Computing Tutorial\"](https://hpc.llnl.gov/documentation/tutorials/introduction-parallel-computing-tutorial)* disponible en el sitio web del *Laboratorio Nacional Lawrence Livermore* (https://hpc.llnl.gov/). Este material se proporciona tal cual, sin garantías de exactitud completa o de la aplicabilidad para un fin particular.\n",
    "\n",
    "A pesar de que se ha hecho un esfuerzo por asegurar la precisión y utilidad de estas notas, los usuarios deben tener en cuenta que los conceptos, aplicaciones y técnicas de la computación paralela están en constante evolución, y se recomienda consultar múltiples fuentes y la documentación oficial más actual para obtener la información más reciente y completa.\n",
    "\n",
    "Por favor, considere que cualquier ejemplo, referencia o cita de \"Introducción a la Computación Paralela\" se proporciona con el objetivo de ilustrar los conceptos y principios básicos de la computación paralela y no debe considerarse como una guía exhaustiva o definitiva sobre el tema.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6488c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel00.jpg?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe65cd",
   "metadata": {},
   "source": [
    "## Cómputo paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d927aa",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4177d2",
   "metadata": {},
   "source": [
    "En la era moderna, el modelo convencional de cómputo serial, donde un algoritmo descompone un problema en instrucciones ejecutadas secuencialmente, ha demostrado ser ineficiente para manejar tareas complejas y voluminosas. Esto se debe a la limitación de ejecutar una sola instrucción a la vez, lo que resulta en una subutilización significativa de los recursos de hardware.\n",
    "\n",
    "El cómputo paralelo surge como una solución eficaz a este problema. Utiliza múltiples elementos de procesamiento de manera simultánea para resolver un problema, descomponiéndolo en partes que pueden ser procesadas al mismo tiempo. Esto no solo acelera el tiempo de ejecución, sino que también maximiza la utilización del hardware disponible.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel01.webp?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Imagina que tienes un gran problema que resolver y estás solo. Necesitas calcular la raíz cuadrada de ocho números diferentes. ¿A qué te dedicas? Bueno, no tienes muchas opciones. Comienzas con el primer número y calculas el resultado. Luego sigues con los demás.\n",
    "\n",
    "¿Qué pasa si tienes tres amigos buenos en matemáticas dispuestos a ayudarte? Cada uno de ellos calculará la raíz cuadrada de dos números y tu trabajo será más fácil porque la carga de trabajo se distribuye equitativamente entre tus amigos. Esto significa que su problema se resolverá más rápido.\n",
    "\n",
    "Bien, ¿está todo claro? En estos ejemplos, cada amigo representa un núcleo de la CPU. En el primer ejemplo, usted resuelve toda la tarea de forma secuencial. Esto se llama computación en serie . En el segundo ejemplo, como estás trabajando con cuatro núcleos en total, estás usando computación paralela . La computación paralela implica el uso de procesos paralelos o procesos que se dividen entre múltiples núcleos en un procesador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb4a94",
   "metadata": {},
   "source": [
    "### Cómputo Serial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a400e",
   "metadata": {},
   "source": [
    "Tradicionalmente, el software ha sido escrito para el cómputo serial:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel02.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "- Un problema se descompone en una serie discreta de instrucciones.\n",
    "- Las instrucciones se ejecutan secuencialmente, una tras otra.\n",
    "- Se ejecuta en un solo procesador.\n",
    "- Solo una instrucción puede ejecutarse en cualquier momento dado.\n",
    "\n",
    "por ejemplo: Ejemplo de cómputo serial en el procesamiento de nóminas.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel03.gif?raw=true\" width=\"500\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b6bea",
   "metadata": {},
   "source": [
    "### Cómputo Paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dcedba",
   "metadata": {},
   "source": [
    "En el sentido más simple, el cómputo paralelo es el uso simultáneo de múltiples recursos computacionales para resolver un problema computacional:\n",
    "\n",
    "- Un problema se divide en partes discretas que pueden resolverse de manera concurrente.\n",
    "- Cada parte se desglosa aún más en una serie de instrucciones.\n",
    "- Las instrucciones de cada parte se ejecutan simultáneamente en diferentes procesadores.\n",
    "- Se emplea un mecanismo general de control y coordinación.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel04.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Por ejemplo: Ejemplo de cómputo paralelo en el procesamiento de nóminas.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel05.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "El problema computacional debería poder:\n",
    "- Descomponerse en piezas discretas de trabajo que puedan resolverse simultáneamente;\n",
    "- Ejecutar múltiples instrucciones del programa en cualquier momento;\n",
    "- Resolverse en menos tiempo con múltiples recursos computacionales que con un solo recurso computacional.\n",
    "\n",
    "Los recursos computacionales son típicamente:\n",
    "- Una única computadora con múltiples procesadores/núcleos (su computador personal).\n",
    "- Un número arbitrario de dichas computadoras conectadas por una red (computadores de una sala de cómputo, de una oficina, o un esquema tipo [Beowulf](https://en.wikipedia.org/wiki/Beowulf_cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd8563",
   "metadata": {},
   "source": [
    "### Computadoras Paralelas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521b367",
   "metadata": {},
   "source": [
    "Prácticamente todas las computadoras independientes actuales son paralelas desde una perspectiva de hardware:\n",
    "- Múltiples unidades funcionales (caché L1, caché L2, ramificación, precarga, decodificación, procesamiento de punto flotante, procesamiento gráfico (GPU), entero, etc.)\n",
    "- Múltiples unidades de ejecución/núcleos\n",
    "- Múltiples hilos de hardware\n",
    "Las redes conectan múltiples computadoras independientes (nodos) para formar clústeres de computadoras paralelas más grandes.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel07.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Por ejemplo, el gráfico a continuación muestra un clúster típico de computadoras paralelas:\n",
    "- Cada nodo de cómputo es en sí mismo una computadora paralela de múltiples procesadores\n",
    "- Múltiples nodos de cómputo están interconectados con una red Infiniband\n",
    "- Nodos de propósito especial, también de múltiples procesadores, se utilizan para otros fines\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel08.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "La mayoría de las grandes computadoras paralelas del mundo (supercomputadoras) son clústeres de hardware producidos por un puñado de proveedores (en su mayoría) bien conocidos. [Top500.org](https://www.top500.org/statistics/list/)\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel09.PNG?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel10.PNG?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284cfdf",
   "metadata": {},
   "source": [
    "## Conceptos y Terminología"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98899dae",
   "metadata": {},
   "source": [
    "### Arquitectura de Computadoras von Neumann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f4958",
   "metadata": {},
   "source": [
    "- Nombrada en honor al matemático húngaro [John von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann), quien fue el primero en formular los requisitos generales para una computadora electrónica en sus trabajos de 1945.\n",
    "- También conocida como \"computadora de programa almacenado\" - tanto las instrucciones del programa como los datos se mantienen en memoria electrónica. Difiere de las computadoras anteriores que se programaban mediante \"cableado fijo\".\n",
    "- Desde entonces, prácticamente todas las computadoras han seguido este diseño básico:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel11.gif?raw=true\" width=\"150\" />\n",
    "</p>\n",
    "\n",
    "- Compuesta de cuatro componentes principales:\n",
    "    - Memoria\n",
    "    - Unidad de Control\n",
    "    - Unidad de Lógica Aritmética\n",
    "    - Entrada/Salida\n",
    "- Se utiliza memoria de acceso aleatorio de lectura/escritura para almacenar tanto las instrucciones del programa como los datos.\n",
    "- Las instrucciones del programa son datos codificados que le indican a la computadora qué hacer.\n",
    "- Los datos son simplemente información que será utilizada por el programa.\n",
    "- La unidad de control recupera instrucciones/datos de la memoria, decodifica las instrucciones y luego coordina secuencialmente las operaciones para realizar la tarea programada.\n",
    "- La Unidad Aritmética realiza operaciones aritméticas básicas.\n",
    "- Entrada/Salida es la interfaz con el operador humano.\n",
    "Las computadoras paralelas aún siguen este diseño básico, solo que multiplicado en unidades. La arquitectura básica y fundamental permanece igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9ee77",
   "metadata": {},
   "source": [
    "### Taxonomía Clásica de Flynn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a9f1c",
   "metadata": {},
   "source": [
    "Existen numerosas formas de clasificar las computadoras paralelas. Ejemplos de estas están disponibles en las referencias.\n",
    "Una de las clasificaciones más utilizadas, vigente desde 1966, es la llamada [Taxonomía de Flynn](https://en.wikipedia.org/wiki/Flynn%27s_taxonomy).\n",
    "La taxonomía de Flynn distingue las arquitecturas de computadoras multiprocesador según cómo se pueden clasificar a lo largo de las dos dimensiones independientes de Flujo de Instrucciones y Flujo de Datos. Cada una de estas dimensiones puede tener solo uno de dos estados posibles: Único o Múltiple.\n",
    "La matriz a continuación define las 4 posibles clasificaciones según [Flynn](https://en.wikipedia.org/wiki/Michael_J._Flynn):\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel12.gif?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe109b",
   "metadata": {},
   "source": [
    "#### Instrucción Única, Dato Único (SISD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6816793",
   "metadata": {},
   "source": [
    "- Una computadora serial (no paralela)\n",
    "- Instrucción Única: Solo un flujo de instrucciones es procesado por la CPU durante cada ciclo de reloj.\n",
    "- Dato Único: Solo un flujo de datos se utiliza como entrada durante cada ciclo de reloj.\n",
    "- Ejecución determinista.\n",
    "- Este es el tipo más antiguo de computadora.\n",
    "- Ejemplos: mainframes de generaciones anteriores, minicomputadoras, estaciones de trabajo y PCs con un único procesador/núcleo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel13.gif?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel14.gif?raw=true\" width=\"100\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel15.PNG?raw=true\" width=\"750\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ff196",
   "metadata": {},
   "source": [
    "#### Instrucción Única, Datos Múltiples (Single Instruction, Multiple Data, SIMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfacb57",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- ***Instrucción Única:*** Todas las unidades de procesamiento ejecutan la misma instrucción en cualquier ciclo de reloj dado.  \n",
    "- ***Datos Múltiples:*** Cada unidad de procesamiento puede operar sobre un elemento de datos diferente.  \n",
    "- Mejor adecuado para problemas especializados caracterizados por un alto grado de regularidad, como el procesamiento de gráficos/imagen.  \n",
    "- Ejecución sincrónica (en paso bloqueado) y determinista.  \n",
    "- ***Dos variedades:*** Arreglos de Procesadores y Tubos de Vector.  \n",
    "\n",
    "***Ejemplos:***\n",
    "- ***Arreglos de Procesadores:*** Thinking Machines CM-2, MasPar MP-1 & MP-2, ILLIAC IV.\n",
    "- ***Canales de Vectores:*** IBM 9000, Cray X-MP, Y-MP & C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10.\n",
    "La mayoría de las computadoras modernas, especialmente aquellas con unidades de procesamiento gráfico (GPUs), emplean instrucciones y unidades de ejecución SIMD.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel16.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel17.PNG?raw=true\" width=\"750\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25694e28",
   "metadata": {},
   "source": [
    "#### Instrucción Múltiple, Dato Único (Multiple Instruction, Single Data, MISD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915bfcd",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- ***Instrucción Múltiple:*** Cada unidad de procesamiento opera sobre los datos de manera independiente mediante flujos de instrucciones separados.\n",
    "- ***Dato Único:*** Un único flujo de datos se introduce en múltiples unidades de procesamiento.\n",
    "- Pocos (si acaso alguno) ejemplos reales de esta clase de computadora paralela han existido.\n",
    "- Algunos usos concebibles podrían ser:\n",
    "  - múltiples filtros de frecuencia operando sobre un único flujo de señal\n",
    "  - múltiples algoritmos de criptografía intentando descifrar un único mensaje codificado.\n",
    "  \n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel18.PNG?raw=true\" width=\"750\" />\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091703bf",
   "metadata": {},
   "source": [
    "#### Instrucción Múltiple, Datos Múltiples (Multiple Instruction, Multiple Data, MIMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d6a3f",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- Instrucción Múltiple: Cada procesador puede estar ejecutando un flujo de instrucciones diferente.\n",
    "- Datos Múltiples: Cada procesador puede estar trabajando con un flujo de datos diferente.\n",
    "- La ejecución puede ser sincrónica o asincrónica, determinista o no determinista.\n",
    "- Actualmente, es el tipo más común de computadora paralela; la mayoría de las supercomputadoras modernas entran en esta categoría.\n",
    "\n",
    "- ***Ejemplos:*** la mayoría de las supercomputadoras actuales, clústeres de computadoras paralelas en red y \"grids\", computadoras SMP (Symmetric Multi-Processing) de múltiples procesadores, PCs de múltiples núcleos.\n",
    "\n",
    "***Nota:*** Muchas arquitecturas MIMD también incluyen subcomponentes de ejecución SIMD.\n",
    "\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel19.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel20.PNG?raw=true\" width=\"750\" />\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be90c4",
   "metadata": {},
   "source": [
    "### Terminología General de Cómputo Paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256ffc5",
   "metadata": {},
   "source": [
    "Como todo lo demás, el cómputo paralelo tiene su propio argot. A continuación, se enumeran algunos de los términos más comúnmente asociados con el cómputo paralelo. La mayoría de estos serán discutidos con más detalle más adelante.\n",
    "\n",
    "- **CPU:** Las CPU contemporáneas consisten en uno o más núcleos: una unidad de ejecución distinta con su propio flujo de instrucciones. Los núcleos dentro de una CPU pueden estar organizados en uno o más sockets, cada uno con su propia memoria distinta. Cuando una CPU consta de dos o más sockets, usualmente la infraestructura de hardware soporta el compartir memoria a través de los sockets.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Nodo (Node):** Un \"computador en una caja\" autónomo. Usualmente compuesto por múltiples CPU/procesadores/núcleos, memoria, interfaces de red, etc. Los nodos están interconectados para formar una supercomputadora.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Tarea (Task):** Una sección de trabajo computacional lógicamente discreta. Una tarea es típicamente un programa o un conjunto de instrucciones tipo programa que es ejecutado por un procesador. Un programa paralelo consta de múltiples tareas corriendo en múltiples procesadores.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Tubería de Procesamiento (Pipelining):** División de una tarea en pasos realizados por diferentes unidades procesadoras, con entradas fluyendo a través, muy parecido a una línea de montaje; un tipo de cómputo paralelo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Memoria Compartida (Shared Memory):** Describe una arquitectura de computadora donde todos los procesadores tienen acceso directo a una memoria física común. En un sentido de programación, describe un modelo donde las tareas paralelas tienen la misma \"imagen\" de memoria y pueden direccionar y acceder directamente a las mismas ubicaciones de memoria lógica, independientemente de donde la memoria física exista realmente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Procesador Simétrico Múltiple (Symmetric Multi-Processor, SMP):** Arquitectura de hardware de memoria compartida donde múltiples procesadores comparten un único espacio de direcciones y tienen igual acceso a todos los recursos: memoria, disco, etc.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Memoria Distribuida (Distributed Memory):** En hardware, se refiere al acceso a memoria basado en red para memoria física que no es común. Como modelo de programación, las tareas solo pueden \"ver\" lógicamente la memoria local de la máquina y deben usar comunicaciones para acceder a la memoria en otras máquinas donde otras tareas están ejecutando.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Comunicaciones:** Las tareas paralelas típicamente necesitan intercambiar datos. Esto puede lograrse de varias maneras, como a través de un bus de memoria compartido o sobre una red.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Sincronización:** La coordinación de tareas paralelas en tiempo real, muy a menudo asociada con comunicaciones. La sincronización usualmente implica la espera por parte de al menos una tarea, y por lo tanto puede causar un aumento en el tiempo de ejecución en reloj de una aplicación paralela.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Granularidad Computacional (Computational Granularity):** En cómputo paralelo, la granularidad es una medida cuantitativa o cualitativa de la relación de cálculo a comunicación.\n",
    "\n",
    "  - **Gruesa:** cantidades relativamente grandes de trabajo computacional se realizan entre eventos de comunicación.\n",
    "  - **Fina:** cantidades relativamente pequeñas de trabajo computacional se realizan entre eventos de comunicación.\n",
    "  \n",
    "  \n",
    "La siguiente tabla resume las características principales de la granularidad gruesa y fina en el contexto del cómputo paralelo:\n",
    "\n",
    "| Característica            | Granularidad Gruesa                                       | Granularidad Fina                                         |\n",
    "|---------------------------|-----------------------------------------------------------|-----------------------------------------------------------|\n",
    "| **Tamaño de la Tarea**    | Grandes, abarcan mucho trabajo computacional.             | Pequeñas, abarcan menos trabajo computacional.            |\n",
    "| **Comunicación**          | Menor frecuencia de comunicación entre tareas.            | Mayor frecuencia de comunicación entre tareas.            |\n",
    "| **Sincronización**        | Menor necesidad de sincronización frecuente.              | Mayor necesidad de sincronización frecuente.              |\n",
    "| **Overhead**              | Menor overhead de comunicación y sincronización.          | Mayor overhead debido a la comunicación y sincronización. |\n",
    "| **Balance de Carga**      | Potencial desbalance de carga entre procesadores.         | Facilita un balance de carga más uniforme.                |\n",
    "| **Escalabilidad**         | Mejor escalabilidad en problemas con independencia.       | Escalabilidad limitada por la comunicación intensiva.     |\n",
    "| **Ejemplo de Aplicación** | Procesamiento de imágenes completas en paralelo.          | Cálculos de interacción de partículas en física.          |\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Aceleración Observada (speedup):** Es uno de los indicadores más simples y ampliamente usados para el rendimiento de un programa paralelo. Determina la aceleración observada de un código que ha sido paralelizado, definida como:\n",
    "\n",
    "$$\\frac{\\text{tiempo de ejecución en serie}}{\\text{tiempo de ejecución paralelo}}$$\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel30.png?raw=true\" width=\"350\" />\n",
    "</p>  \n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Sobrecarga Paralela (Overhead):** Tiempo de ejecución requerido que es único para tareas paralelas, en contraposición al que se hace para trabajo útil. La sobrecarga paralela puede incluir factores como:\n",
    "\n",
    "  - Tiempo de inicio de tarea\n",
    "  - Sincronizaciones\n",
    "  - Comunicaciones de datos\n",
    "  - Sobrecarga de software impuesta por lenguajes paralelos, bibliotecas, sistema operativo, etc.\n",
    "  - Tiempo de terminación de tarea\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Masivamente Paralelo:** Se refiere al hardware que comprende un sistema paralelo dado: tener muchos elementos de procesamiento. El significado de \"muchos\" sigue aumentando, pero actualmente, las computadoras paralelas más grandes están compuestas por elementos de procesamiento que se cuentan por cientos de miles hasta millones.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Paralelo Embarazosamente (Embarrassingly):** Resolver muchas tareas similares, pero independientes, simultáneamente; poca o ninguna necesidad de coordinación entre las tareas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Escalabilidad:** Se refiere a la capacidad de un sistema paralelo (hardware y/o software) para demostrar un aumento proporcional en la aceleración paralela con la adición de más recursos. Factores que contribuyen a la escalabilidad incluyen:\n",
    "\n",
    "  - Hardware: particularmente anchos de banda de memoria-CPU y propiedades de comunicación de red.\n",
    "  - Algoritmo de aplicación.\n",
    "  - Relacionados con la sobrecarga paralela.\n",
    "  - Características de su aplicación específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2a814",
   "metadata": {},
   "source": [
    "### Beneficios Potenciales, Límites y Costos de la Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c750fd",
   "metadata": {},
   "source": [
    "#### Ley de Amdahl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6757",
   "metadata": {},
   "source": [
    "La [Ley de Amdahl](https://en.wikipedia.org/wiki/Amdahl%27s_law) establece que la aceleración potencial del programa está definida por la fracción de código ($P$) que puede ser paralelizado:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel21.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "$$\\text{speedup}=\\frac{1}{1-P}$$\n",
    "\n",
    "- Si ninguna parte del código puede ser paralelizado, $P = 0$ y el $speedup = 1$ (sin aceleración).\n",
    "- Si todo el código es paralelizado, $P = 1$ y el speedup (aceleración) es infinito (en teoría).\n",
    "- Si el $50\\%$ del código puede ser paralelizado, $speedup_{max}=2$, lo que significa que el código se ejecutará dos veces más rápido.\n",
    "\n",
    "Introduciendo el número de procesadores que realizan la fracción paralela del trabajo, la relación se puede modelar por:\n",
    "\n",
    "$$\\text{speedup}=\\frac{1}{\\frac{P}{N}+S}$$\n",
    "\n",
    "donde $P$ = fracción paralela, $N$ = número de procesadores y $S$ = fracción serial.\n",
    "Pronto se hace evidente que hay límites para la escalabilidad del paralelismo. Por ejemplo:\n",
    "\n",
    "```\n",
    "                         aceleración\n",
    "              -------------------------------------\n",
    "        N     P = .50   P = .90   P = .95   P = .99\n",
    "      -----   -------   -------   -------   -------\n",
    "         10      1.82      5.26      6.89      9.17\n",
    "        100      1.98      9.17     16.80     50.25    \n",
    "      1,000      1.99      9.91     19.62     90.99\n",
    "     10,000      1.99      9.91     19.96     99.02\n",
    "    100,000      1.99      9.99     19.99     99.90\n",
    "```\n",
    "- ***Cita \"famosa\":*** *¡Puedes pasar una vida intentando paralelizar el 95% de tu código, y nunca lograrás más de 20 veces de aceleración sin importar cuántos procesadores utilices!* \n",
    "\n",
    "Sin embargo, ciertos problemas demuestran un aumento en el rendimiento al incrementar el tamaño del problema. Por ejemplo:\n",
    "\n",
    "```\n",
    "        Cálculos de Malla 2D\n",
    "        Fracción Paralela        85 segundos 85%   \n",
    "        Fracción Serial          15 segundos   15%   \n",
    "        \n",
    "```\n",
    "\n",
    "Podemos aumentar el tamaño del problema duplicando las dimensiones de la malla y dividiendo a la mitad el paso de tiempo. Esto resulta en cuatro veces la cantidad de puntos de la malla y el doble de número de pasos de tiempo. Los tiempos entonces se ven así:  \n",
    "\n",
    "```\n",
    "        Cálculos de Malla 2D \n",
    "        Fracción Paralela         680 segundos 97.84%   \n",
    "        Fracción Serial           15 segundos    2.16%   \n",
    "```\n",
    "\n",
    "Problemas que aumentan el porcentaje de tiempo paralelo con su tamaño son más escalables que problemas con un porcentaje fijo de tiempo paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4b2eb",
   "metadata": {},
   "source": [
    "#### Complejidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0a10a",
   "metadata": {},
   "source": [
    "En general, las aplicaciones paralelas son más complejas que las aplicaciones seriales correspondientes. No solo se tienen múltiples flujos de instrucciones ejecutándose al mismo tiempo, sino que también se tiene el flujo de datos entre ellos.\n",
    "Los costos de la complejidad se miden en tiempo de programador en prácticamente todos los aspectos del ciclo de desarrollo de software:\n",
    "- Diseño\n",
    "- Codificación\n",
    "- Depuración\n",
    "- Afinación\n",
    "- Mantenimiento  \n",
    "\n",
    "Adherirse a las \"buenas\" prácticas de desarrollo de software es esencial al desarrollar aplicaciones paralelas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e62acc",
   "metadata": {},
   "source": [
    "#### Portabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015a718",
   "metadata": {},
   "source": [
    "Gracias a la estandarización en varias APIs, como MPI, OpenMP y los hilos POSIX, los problemas de portabilidad con programas paralelos no son tan graves como en años pasados. Sin embargo,\n",
    "todos los problemas habituales de portabilidad asociados con programas seriales se aplican a programas paralelos. Por ejemplo, si se utilizan \"mejoras\" de un proveedor a Fortran, C o C++, la portabilidad será un problema.  \n",
    "\n",
    "A pesar de que existen estándares para varias APIs, las implementaciones difieren en varios detalles, a veces hasta el punto de requerir modificaciones del código para efectuar la portabilidad.  \n",
    "\n",
    "Los sistemas operativos pueden jugar un papel clave en los problemas de portabilidad del código.\n",
    "Las arquitecturas de hardware son característicamente muy variables y pueden afectar la portabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d13ff4",
   "metadata": {},
   "source": [
    "#### Requisitos de Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86929ab",
   "metadata": {},
   "source": [
    "La intención principal de la programación paralela es disminuir el tiempo de ejecución en reloj de pared, sin embargo, para lograr esto, se requiere más tiempo de CPU. Por ejemplo, un código paralelo que se ejecuta en 1 hora en 8 procesadores en realidad utiliza 8 horas de tiempo de CPU.  \n",
    "\n",
    "La cantidad de memoria requerida puede ser mayor para códigos paralelos que para códigos seriales, debido a la necesidad de replicar datos y por los sobrecargos asociados con bibliotecas de soporte paralelo y subsistemas.  \n",
    "\n",
    "Para programas paralelos de corta duración, en realidad puede haber una disminución en el rendimiento en comparación con una implementación serial similar. Los costos de sobrecarga asociados con la configuración del entorno paralelo, la creación de tareas, las comunicaciones y la terminación de tareas pueden constituir una parte significativa del tiempo total de ejecución para ejecuciones cortas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619a827",
   "metadata": {},
   "source": [
    "#### Escalabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102d3c1",
   "metadata": {},
   "source": [
    "Dos tipos de escalabilidad basados en el tiempo hasta la solución: escalabilidad fuerte y escalabilidad débil.  \n",
    "\n",
    "- ***Escalabilidad Fuerte (Amdahl):***\n",
    "  - El tamaño total del problema permanece fijo a medida que se agregan más procesadores.\n",
    "  - El objetivo es ejecutar el mismo tamaño de problema más rápido.\n",
    "  - La escalabilidad perfecta significa que el problema se resuelve en tiempo $1/P$ (en comparación con serial).  \n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Escalabilidad Débil (Gustafson):***\n",
    "  - El tamaño del problema por procesador se mantiene fijo a medida que se agregan más procesadores. El tamaño total del problema es proporcional al número de procesadores utilizados.\n",
    "  - El objetivo es ejecutar un problema más grande en la misma cantidad de tiempo.\n",
    "  - La escalabilidad perfecta significa que el problema $Px$ se ejecuta en el mismo tiempo que una ejecución de un solo procesador.  \n",
    "\n",
    "La capacidad de rendimiento de un programa paralelo para escalar es el resultado de una serie de factores interrelacionados. Simplemente agregar más procesadores rara vez es la respuesta.  \n",
    "\n",
    "El algoritmo puede tener límites inherentes a la escalabilidad. En algún punto, agregar más recursos causa una disminución en el rendimiento. Esta es una situación común con muchas aplicaciones paralelas.  \n",
    "\n",
    "Los factores de hardware juegan un papel significativo en la escalabilidad. Ejemplos:\n",
    "- Ancho de banda del bus memoria-CPU en una máquina SMP\n",
    "- Ancho de banda de la red de comunicaciones\n",
    "- Cantidad de memoria disponible en una máquina dada o un conjunto de máquinas\n",
    "- Velocidad del reloj del procesador  \n",
    "\n",
    "Las bibliotecas de soporte paralelo y el software de subsistemas pueden limitar la escalabilidad independientemente de su aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bf420",
   "metadata": {},
   "source": [
    "## Arquitecturas de Memoria en Computadoras Paralelas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b1870",
   "metadata": {},
   "source": [
    "### Memoria Compartida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8055d35",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04507da4",
   "metadata": {},
   "source": [
    "- Las computadoras paralelas con memoria compartida varían ampliamente, pero generalmente tienen en común la capacidad de todos los procesadores para acceder a toda la memoria como un espacio de direcciones global.  \n",
    "\n",
    "- Varios procesadores pueden operar de manera independiente pero comparten los mismos recursos de memoria.  \n",
    "\n",
    "- Los cambios en una ubicación de memoria realizados por un procesador son visibles para todos los demás procesadores.  \n",
    "- Históricamente, las máquinas de memoria compartida han sido clasificadas como UMA y NUMA, basándose en los tiempos de acceso a la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699d43",
   "metadata": {},
   "source": [
    "#### Acceso Uniforme a la Memoria (Uniform Memory Access , UMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd46707",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel22.gif?raw=true\" width=\"300\" />\n",
    "</p>  \n",
    "\n",
    "- Hoy en día, comúnmente representado por máquinas Multiprocesador Simétrico (SMP)  \n",
    "- Procesadores idénticos  \n",
    "- Acceso igual y tiempos de acceso a la memoria  \n",
    "- A veces llamado CC-UMA - UMA Coherente en Caché. Coherente en caché significa que si un procesador actualiza una ubicación en la memoria compartida, todos los demás procesadores conocen la actualización. La coherencia de caché se logra a nivel de hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d77db",
   "metadata": {},
   "source": [
    "#### Acceso No Uniforme a la Memoria (Non-Uniform Memory Access, NUMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c608d",
   "metadata": {},
   "source": [
    "- A menudo se realiza mediante la conexión física de dos o más SMP (Multiprocesadores Simétricos).\n",
    "- Un SMP puede acceder directamente a la memoria de otro SMP.\n",
    "- No todos los procesadores tienen el mismo tiempo de acceso a todas las memorias.\n",
    "- El acceso a la memoria a través del enlace es más lento.\n",
    "- Si se mantiene la coherencia de caché, entonces también puede llamarse CC-NUMA - NUMA Coherente en Caché.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel23.gif?raw=true\" width=\"350\" />\n",
    "</p>  \n",
    "\n",
    "**Ventajas**\n",
    "- El espacio de direcciones global proporciona una perspectiva de programación amigable para el usuario hacia la memoria.\n",
    "- El intercambio de datos entre tareas es rápido y uniforme debido a la proximidad de la memoria a las CPU.\n",
    "\n",
    "**Desventajas**\n",
    "- La principal desventaja es la falta de escalabilidad entre la memoria y las CPU. Agregar más CPU puede aumentar geométricamente el tráfico en el camino compartido memoria-CPU y, para sistemas coherentes en caché, aumentar geométricamente el tráfico asociado con la gestión de caché/memoria.\n",
    "- Responsabilidad del programador por construcciones de sincronización que aseguren el acceso \"correcto\" de la memoria global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7f7da",
   "metadata": {},
   "source": [
    "### Memoria Distribuida (Distributed Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0987f",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a920c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel24.gif?raw=true\" width=\"350\" />\n",
    "</p>  \n",
    "\n",
    "Al igual que los sistemas de memoria compartida, los sistemas de memoria distribuida varían ampliamente, pero comparten una característica común. Los sistemas de memoria distribuida requieren una red de comunicación para conectar la memoria entre procesadores.\n",
    "\n",
    "Los procesadores tienen su propia memoria local. Las direcciones de memoria en un procesador no se mapean a otro procesador, por lo que no existe un concepto de espacio de direcciones global en todos los procesadores.\n",
    "\n",
    "Debido a que cada procesador tiene su propia memoria local, opera de manera independiente. Los cambios que realiza en su memoria local no tienen efecto en la memoria de otros procesadores. Por lo tanto, el concepto de coherencia de caché no se aplica.\n",
    "\n",
    "Cuando un procesador necesita acceder a datos en otro procesador, generalmente es tarea del programador definir explícitamente cómo y cuándo se comunican los datos. La sincronización entre tareas también es responsabilidad del programador.\n",
    "\n",
    "La \"tela\" de red utilizada para la transferencia de datos varía ampliamente, aunque puede ser tan simple como Ethernet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704955fb",
   "metadata": {},
   "source": [
    "#### Ventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ec5dd",
   "metadata": {},
   "source": [
    "- La memoria es escalable con el número de procesadores. Aumente el número de procesadores y el tamaño de la memoria aumenta proporcionalmente.  \n",
    "- Cada procesador puede acceder rápidamente a su propia memoria sin interferencias y sin los costos generados al tratar de mantener la coherencia global de la caché.  \n",
    "- Efectividad en costos: puede usar procesadores y redes comerciales disponibles en el mercado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845ef10",
   "metadata": {},
   "source": [
    "#### Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707304c6",
   "metadata": {},
   "source": [
    "- El programador es responsable de muchos detalles asociados con la comunicación de datos entre procesadores.  \n",
    "\n",
    "- Puede ser difícil mapear estructuras de datos existentes, basadas en memoria global, a esta organización de memoria.  \n",
    "\n",
    "- Tiempos de acceso a la memoria no uniformes: los datos que residen en un nodo remoto tardan más en accederse que los datos locales al nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051a836",
   "metadata": {},
   "source": [
    "### Memoria Híbrida Distribuida-Compartida (Hybrid Distributed-Shared Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7772d6c",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9330f5e",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel25.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "- Las computadoras más grandes y rápidas del mundo hoy en día emplean tanto arquitecturas de memoria compartida como distribuida.  \n",
    "\n",
    "- El componente de memoria compartida puede ser una máquina de memoria compartida y/o unidades de procesamiento gráfico (GPU).  \n",
    "\n",
    "- El componente de memoria distribuida es la interconexión de múltiples máquinas de memoria compartida/GPU, que solo conocen su propia memoria, no la memoria en otra máquina. Por lo tanto, se requieren comunicaciones de red para mover datos de una máquina a otra.  \n",
    "\n",
    "- Las tendencias actuales parecen indicar que este tipo de arquitectura de memoria continuará predominando y aumentando en el ámbito de la computación de alto rendimiento en el futuro previsible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165811",
   "metadata": {},
   "source": [
    "#### Ventajas y Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b53ea",
   "metadata": {},
   "source": [
    "Lo que es común tanto a las arquitecturas de memoria compartida como distribuida.\n",
    "\n",
    "- **Ventajas:**\n",
    "  - **Escalabilidad aumentada:** Un aspecto importante de la memoria híbrida es la capacidad de escalar más eficientemente al combinar los beneficios de ambas arquitecturas, permitiendo manejar eficazmente grandes volúmenes de datos y procesamiento intensivo.\n",
    "<p>&nbsp;</p>\n",
    "  \n",
    "- **Desventajas:**\n",
    "  - **Complejidad aumentada para el programador:** La necesidad de gestionar dos tipos diferentes de arquitecturas de memoria puede complicar significativamente el diseño y la implementación del software. Los programadores deben ser conscientes de dónde y cómo se almacenan los datos, además de manejar la comunicación entre diferentes unidades de memoria.\n",
    "\n",
    "Este enfoque híbrido ofrece un equilibrio entre el acceso rápido a memoria local en las máquinas individuales y la capacidad de trabajar en conjunto en tareas más grandes que requieren datos de múltiples fuentes, aprovechando así las fortalezas de ambos tipos de memoria para mejorar el rendimiento general y la eficiencia del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e6135",
   "metadata": {},
   "source": [
    "## Modelos de Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24cd38",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c9dc4",
   "metadata": {},
   "source": [
    "Existen varios modelos de programación paralela de uso común:\n",
    "\n",
    "- Memoria Compartida (sin hilos, threads)\n",
    "- Hilos\n",
    "- Memoria Distribuida / Paso de Mensajes\n",
    "- Paralelismo de Datos\n",
    "- Híbrido\n",
    "- Programa Único Múltiples Datos (SPMD)\n",
    "- Múltiples Programas Múltiples Datos (MPMD)\n",
    "\n",
    "Los modelos de programación paralela existen como una abstracción por encima de las arquitecturas de hardware y memoria. Aunque puede no parecer evidente, estos modelos NO son específicos de un tipo particular de máquina o arquitectura de memoria. De hecho, cualquiera de estos modelos puede (teóricamente) implementarse en cualquier hardware subyacente. A continuación, se discuten dos ejemplos del pasado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5433a",
   "metadata": {},
   "source": [
    "### Modelo de memoria compartida en una máquina de memoria distribuida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7437bce",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel26.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "Enfoque *ALLCACHE de Kendall Square Research* (*KSR*). La memoria de la máquina estaba físicamente distribuida a través de máquinas en red, pero aparecía para el usuario como un espacio de direcciones de memoria compartida global. Genéricamente, este enfoque se conoce como \"memoria compartida virtual\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ab55a",
   "metadata": {},
   "source": [
    "### Modelo de memoria distribuida en una máquina de memoria compartida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a91d3",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel27.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "[Interface de Paso de Mensajes](https://en.wikipedia.org/wiki/Message_Passing_Interface) (Message Passing Interface, MPI) en SGI Origin 2000. El SGI Origin 2000 empleaba el tipo de arquitectura de memoria compartida CC-NUMA, donde cada tarea tiene acceso directo al espacio de direcciones global distribuido en todas las máquinas. Sin embargo, la capacidad de enviar y recibir mensajes usando MPI, como se hace comúnmente en una red de máquinas de memoria distribuida, fue implementada y comúnmente utilizada.\n",
    "\n",
    "¿Qué modelo usar? Esto es a menudo una combinación de lo que está disponible y elección personal. No hay un modelo \"mejor\", aunque ciertamente hay implementaciones mejores de algunos modelos sobre otros.\n",
    "\n",
    "Las siguientes secciones describen cada uno de los modelos mencionados anteriormente y también discuten algunas de sus implementaciones reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07372f2",
   "metadata": {},
   "source": [
    "### Modelo de Memoria Compartida (sin hilos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a3c67",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel28.gif?raw=true\" width=\"200\" />\n",
    "</p>  \n",
    "\n",
    "En este modelo de programación, los procesos o tareas comparten un espacio de direcciones común, al cual leen y escriben de manera asincrónica.  \n",
    "\n",
    "Se utilizan varios mecanismos como cerrojos y semáforos para controlar el acceso a la memoria compartida, resolver contiendas y prevenir condiciones de carrera y bloqueos mutuos (deadlocks).\n",
    "Este es quizás el modelo de programación paralela más simple.\n",
    "\n",
    "Una ventaja de este modelo desde el punto de vista del programador es que la noción de \"propiedad\" de datos no existe, por lo que no es necesario especificar explícitamente la comunicación de datos entre tareas. Todos los procesos ven y tienen igual acceso a la memoria compartida. El desarrollo del programa a menudo puede ser simplificado.\n",
    "\n",
    "Una desventaja importante en términos de rendimiento es que se vuelve más difícil entender y gestionar la localidad de los datos:\n",
    "- Mantener los datos locales al proceso que trabaja en ellos conserva los accesos a la memoria, las actualizaciones de caché y el tráfico del bus que ocurre cuando múltiples procesos usan los mismos datos.\n",
    "- Desafortunadamente, controlar la localidad de los datos es difícil de entender y puede estar más allá del control del usuario promedio.\n",
    "\n",
    "***Implementaciones***\n",
    "\n",
    "- En máquinas de memoria compartida independientes, los sistemas operativos nativos, compiladores y/o hardware proporcionan soporte para la programación de memoria compartida. Por ejemplo, el estándar POSIX proporciona una API para usar memoria compartida, y UNIX ofrece segmentos de memoria compartida (shmget, shmat, shmctl, etc.).  \n",
    "\n",
    "- En máquinas de memoria distribuida, la memoria está físicamente distribuida a través de una red de máquinas, pero se hace global a través de hardware y software especializado. Hay disponibles varias implementaciones de [SHMEM](http://en.wikipedia.org/wiki/SHMEM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03980d",
   "metadata": {},
   "source": [
    "### El modelo de hilos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593ba4d",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38e0419",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel29.PNG?raw=true\" width=\"200\" />\n",
    "</p>  \n",
    "\n",
    "Este modelo de programación es un tipo de programación de memoria compartida.\n",
    "\n",
    "En el modelo de hilos de programación paralela, un único proceso \"pesado\" puede tener múltiples rutas de ejecución \"ligeras\" y concurrentes.\n",
    "\n",
    "Por ejemplo:\n",
    "- El programa principal `a.out` es programado para ejecutarse por el sistema operativo nativo. `a.out` carga y adquiere todos los recursos necesarios del sistema y del usuario para ejecutarse. Este es el proceso \"pesado\".  \n",
    "\n",
    "- `a.out` realiza algún trabajo serial, y luego crea una serie de tareas (hilos) que pueden ser programadas y ejecutadas de forma concurrente por el sistema operativo.  \n",
    "\n",
    "- Cada hilo tiene datos locales, pero también comparte todos los recursos de `a.out`. Esto ahorra la sobrecarga asociada con replicar los recursos de un programa para cada hilo (\"ligero\"). Cada hilo también se beneficia de una vista global de la memoria porque comparte el espacio de memoria de `a.out`.  \n",
    "\n",
    "- El trabajo de un hilo puede describirse mejor como una subrutina dentro del programa principal. Cualquier hilo puede ejecutar cualquier subrutina al mismo tiempo que otros hilos.  \n",
    "\n",
    "- Los hilos se comunican entre sí a través de la memoria global (actualizando ubicaciones de direcciones). Esto requiere constructos de sincronización para asegurar que más de un hilo no esté actualizando la misma dirección global al mismo tiempo.  \n",
    "\n",
    "- Los hilos pueden aparecer y desaparecer, pero `a.out` permanece presente para proporcionar los recursos compartidos necesarios hasta que la aplicación se haya completado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d528151e",
   "metadata": {},
   "source": [
    "#### Implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6495da10",
   "metadata": {},
   "source": [
    "Desde una perspectiva de programación, las implementaciones de hilos comúnmente comprenden:  \n",
    "\n",
    "- Una biblioteca de subrutinas que se llaman desde dentro del código fuente paralelo.  \n",
    "\n",
    "- Un conjunto de directivas de compilador incrustadas en el código fuente serial o paralelo.  \n",
    "\n",
    "En ambos casos, el programador es responsable de determinar el paralelismo (aunque los compiladores a veces pueden ayudar).\n",
    "\n",
    "- Las implementaciones con hilos no son nuevas en la computación. Históricamente, los vendedores de hardware han implementado sus propias versiones propietarias de hilos. Estas implementaciones diferían sustancialmente entre sí, lo que dificultaba a los programadores desarrollar aplicaciones con hilos portátiles.  \n",
    "\n",
    "- Los esfuerzos de estandarización no relacionados han resultado en dos implementaciones muy diferentes de hilos: [Hilos POSIX](https://en.wikipedia.org/wiki/Pthreads) y [OpenMP](https://en.wikipedia.org/wiki/OpenMP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12ff752",
   "metadata": {},
   "source": [
    "#### [Hilos POSIX (Pthreads):](https://hpc-tutorials.llnl.gov/posix/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e16a07",
   "metadata": {},
   "source": [
    "Esta es una opción poderosa para los programadores que necesitan control completo sobre la ejecución del paralelismo. Los Pthreads permiten una gran flexibilidad y control en la gestión de hilos, sincronización, y el manejo de recursos compartidos. Son ampliamente utilizados en entornos donde se necesita un ajuste fino del rendimiento y la gestión de la concurrencia.  \n",
    "\n",
    "- Especificados por el estándar IEEE POSIX 1003.1c (1995). Solo para el lenguaje C.\n",
    "- Parte de los sistemas operativos Unix/Linux\n",
    "- Basado en bibliotecas\n",
    "- Comúnmente referido como Pthreads.\n",
    "- Paralelismo muy explícito; requiere una atención significativa al detalle por parte del programador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c69733",
   "metadata": {},
   "source": [
    "#### [OpenMP:](https://www.openmp.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a45c5f",
   "metadata": {},
   "source": [
    "Este modelo es altamente valorado por su simplicidad y eficacia, especialmente para aquellos que están comenzando con la programación paralela o aquellos que necesitan implementar paralelismo en programas existentes con el mínimo esfuerzo. OpenMP utiliza directivas de compilador para automatizar la creación de hilos, la distribución de tareas y la sincronización, lo que facilita enormemente la tarea del programador. Además, debido a que OpenMP es soportado por muchos compiladores, garantiza un buen nivel de portabilidad entre diferentes plataformas. \n",
    "\n",
    "- Estándar de la industria, definido y respaldado conjuntamente por un grupo de importantes proveedores de hardware y software de computadoras, organizaciones e individuos.\n",
    "- Basado en directivas de compilador\n",
    "- Portátil / multiplataforma, incluyendo plataformas Unix y Windows\n",
    "- Disponible en implementaciones de C/C++ y Fortran\n",
    "- Puede ser muy fácil y simple de usar - proporciona un \"paralelismo incremental\". Puede comenzar con código serial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0064a",
   "metadata": {},
   "source": [
    "Para más información y profundizar en los detalles de cada modelo de programación con hilos, aquí tienes recursos útiles:\n",
    "\n",
    "1. **Tutorial de Hilos POSIX**: Puedes encontrar un tutorial completo sobre Hilos POSIX en el sitio web del Laboratorio Nacional Lawrence Livermore (LLNL) accediendo al documento directamente a través de [este enlace a hpc.llnl.gov](https://hpc.llnl.gov/sites/default/files/2019.08.21.TAU_.pdf). Este tutorial proporcionará una guía detallada sobre cómo implementar y manejar hilos POSIX en tus proyectos de programación.\n",
    "\n",
    "2. **Tutorial de OpenMP**: Para aprender más sobre OpenMP, el Laboratorio Nacional Lawrence Livermore ofrece un tutorial completo que puedes explorar. Visita [la página de tutoriales de OpenMP del LLNL](https://hpc-tutorials.llnl.gov/openmp/) para obtener información práctica y ejemplos de cómo utilizar OpenMP en aplicaciones paralelas, tanto en C/C++ como en Fortran.\n",
    "\n",
    "Estos recursos son excelentes puntos de partida para desarrolladores interesados en la programación paralela, proporcionando tanto fundamentos teóricos como ejemplos prácticos que ayudan a entender mejor cómo implementar estos modelos en diversos entornos y plataformas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d31ed1",
   "metadata": {},
   "source": [
    "#### Modelo de Memoria Distribuida / Paso de Mensajes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632964f0",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel31.gif?raw=true\" width=\"300\" />\n",
    "</p>\n",
    "\n",
    "El modelo de [*Memoria Distribuida / Paso de Mensajes*](https://www.open-mpi.org/) (Distributed Memory / Message Passing Model) demuestra las siguientes características:\n",
    "- Un conjunto de tareas que utilizan su propia memoria local durante el cálculo. Múltiples tareas pueden residir en la misma máquina física y/o en un número arbitrario de máquinas.\n",
    "- Las tareas intercambian datos a través de comunicaciones enviando (*sending*) y recibiendo (*receiving*) mensajes.\n",
    "- La transferencia de datos generalmente requiere operaciones cooperativas que deben ser realizadas por cada proceso. Por ejemplo, una operación de envío debe tener una operación de recepción correspondiente.\n",
    "\n",
    "***Implementaciones:***\n",
    "\n",
    "- Desde una perspectiva de programación, las implementaciones de paso de mensajes generalmente comprenden una biblioteca de subrutinas. Las llamadas a estas subrutinas están incrustadas en el código fuente. El programador es responsable de determinar todo el paralelismo.\n",
    "- Históricamente, una variedad de bibliotecas de paso de mensajes han estado disponibles desde la década de 1980. Estas implementaciones diferían sustancialmente entre sí, lo que dificultaba a los programadores desarrollar aplicaciones portátiles.\n",
    "- En 1992, se formó el Foro MPI con el objetivo principal de establecer una interfaz estándar para las implementaciones de paso de mensajes.\n",
    "- La Parte 1 de la Interfaz de Paso de Mensajes (MPI) fue lanzada en 1994. La Parte 2 (MPI-2) se lanzó en 1996 y MPI-3 en 2012. Todas las especificaciones de MPI están disponibles en la web en http://www.mpi-forum.org/docs/.\n",
    "- MPI es el estándar industrial \"de facto\" para el paso de mensajes, reemplazando virtualmente todas las demás implementaciones de paso de mensajes utilizadas para trabajo de producción. Existen implementaciones de MPI para prácticamente todas las plataformas de computación paralela populares. No todas las implementaciones incluyen todo en MPI-1, MPI-2 o MPI-3.\n",
    "\n",
    "\n",
    "***Más Información***\n",
    "- [Tutorial de MPI](https://hpc-tutorials.llnl.gov/mpi/) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff8ba3",
   "metadata": {},
   "source": [
    "### Modelo de Paralelismo de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a0699",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c9a2dd",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel32.gif?raw=true\" width=\"300\" />\n",
    "</p>\n",
    "\n",
    "También puede ser referido como el modelo de Espacio de Direcciones Globales Particionado (PGAS, por sus siglas en inglés).\n",
    "\n",
    "El modelo de paralelismo de datos demuestra las siguientes características:\n",
    "- El espacio de direcciones se trata de manera global.\n",
    "- La mayor parte del trabajo paralelo se centra en realizar operaciones sobre un conjunto de datos. El conjunto de datos suele organizarse en una estructura común, como un arreglo o un cubo.\n",
    "- Un conjunto de tareas trabaja colectivamente en la misma estructura de datos; sin embargo, cada tarea trabaja en una partición diferente de la misma estructura de datos.\n",
    "- Las tareas realizan la misma operación en su partición de trabajo, por ejemplo, \"sumar 4 a cada elemento del arreglo\".\n",
    "- En arquitecturas de memoria compartida, todas las tareas pueden tener acceso a la estructura de datos a través de la memoria global.\n",
    "- En arquitecturas de memoria distribuida, la estructura de datos global puede dividirse lógica y/o físicamente entre las tareas.\n",
    "\n",
    "Implementaciones:\n",
    "\n",
    "Actualmente, hay varias implementaciones de programación paralela en diversas etapas de desarrollo, basadas en el modelo de *Paralelismo de Datos / PGAS*.\n",
    "- [***Coarray Fortran***](https://en.wikipedia.org/wiki/Coarray_Fortran): un pequeño conjunto de extensiones a [Fortran 95](https://en.wikipedia.org/wiki/Fortran_95_language_features) para programación paralela SPMD. Dependiente del compilador. \n",
    "- ***[Unified Parallel C (UPC)](https://upc.lbl.gov/):*** una extensión del lenguaje de programación C para programación paralela SPMD. Dependiente del compilador. Más información: \n",
    "- [***Global Arrays***](https://en.wikipedia.org/wiki/Global_Arrays): proporciona un entorno de programación al estilo de memoria compartida en el contexto de estructuras de datos de arreglo distribuidas. Biblioteca de dominio público con enlaces para C y Fortran77. \n",
    "- ***[X10](http://x10-lang.org/):*** un lenguaje de programación paralela basado en PGAS que está siendo desarrollado por IBM en el Centro de Investigación Thomas J. Watson. Más información: \n",
    "- ***[Chapel](http://chapel.cray.com/):*** un proyecto de lenguaje de programación paralela de código abierto liderado por Cray. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb4096",
   "metadata": {},
   "source": [
    "#### Modelo Híbrido"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52199753",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel33.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "Un modelo híbrido combina más de uno de los modelos de programación descritos anteriormente.\n",
    "\n",
    "Actualmente, un ejemplo común de un modelo híbrido es la combinación del modelo de paso de mensajes (MPI) con el modelo de hilos (OpenMP).\n",
    "- Los hilos realizan cálculos intensivos utilizando datos locales, en el nodo.\n",
    "- Las comunicaciones entre procesos en diferentes nodos se realizan a través de la red usando MPI.\n",
    "Este modelo híbrido se adapta bien al entorno de hardware más popular (actualmente) de máquinas multinúcleo/clúster.\n",
    "\n",
    "Otro ejemplo similar y cada vez más popular de un modelo híbrido es el uso de MPI con programación CPU-GPU (unidad de procesamiento gráfico).\n",
    "- Las tareas MPI se ejecutan en CPUs utilizando memoria local y comunicándose entre sí a través de una red.\n",
    "- Los cálculos intensivos son delegados a las GPUs en el nodo.\n",
    "- El intercambio de datos entre la memoria local del nodo y las GPUs utiliza CUDA (o algo equivalente).\n",
    "\n",
    "Otros modelos híbridos comunes incluyen:\n",
    "- MPI con Pthreads\n",
    "- MPI con aceleradores no-GPU\n",
    "\n",
    "***Ventajas del Modelo Híbrido***\n",
    "1. **Eficiencia en la utilización de recursos:** Al combinar MPI y OpenMP, por ejemplo, se puede lograr un balance entre la computación intensiva local (optimizada por los hilos) y la comunicación eficiente entre nodos (gestionada por MPI).\n",
    "2. **Escalabilidad:** El modelo híbrido permite escalar aplicaciones tanto verticalmente (dentro del mismo nodo, usando más núcleos o GPU) como horizontalmente (a través de múltiples nodos).\n",
    "3. **Flexibilidad:** Permite a los desarrolladores aprovechar lo mejor de ambos mundos — la eficiencia de memoria y la computación local de los hilos, junto con la capacidad de comunicarse eficientemente a través de nodos distantes.\n",
    "\n",
    "***Desafíos del Modelo Híbrido***\n",
    "1. **Complejidad de la programación:** Manejar dos modelos de programación diferentes puede incrementar la complejidad del desarrollo y la depuración de la aplicación.\n",
    "2. **Optimización:** Requiere un conocimiento profundo de ambas arquitecturas para optimizar el rendimiento y aprovechar al máximo ambos tipos de recursos (CPU y GPU, por ejemplo).\n",
    "3. **Gestión de recursos:** Coordinar la memoria y los cálculos entre diferentes arquitecturas (como CPU y GPU) requiere una gestión cuidadosa para evitar cuellos de botella.\n",
    "\n",
    "El empleo de modelos híbridos está en auge debido a su capacidad para adaptarse a las complejas demandas de las aplicaciones modernas que necesitan tanto un alto rendimiento de cómputo como una gran capacidad de procesamiento de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d6df30",
   "metadata": {},
   "source": [
    "#### SPMD (Single Program Multiple Data) y MPMD (Multiple Program Multiple Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b824af9",
   "metadata": {},
   "source": [
    "Ambos [SPMD](https://en.wikipedia.org/wiki/Single_program,_multiple_data) y [MPMD](https://en.wikipedia.org/wiki/Multiple_instruction,_multiple_data) son modelos de programación paralela de alto nivel que pueden construirse sobre cualquier combinación de los modelos de programación paralela previamente mencionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ca068b",
   "metadata": {},
   "source": [
    "##### SPMD (Single Program Multiple Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bf273e",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel34.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- **PROGRAMA ÚNICO:** Todas las tareas ejecutan su copia del mismo programa simultáneamente. Este programa puede ser de hilos, paso de mensajes, paralelismo de datos o híbrido.\n",
    "- **DATOS MÚLTIPLES:** Todas las tareas pueden utilizar diferentes datos.\n",
    "- Los programas SPMD generalmente tienen la lógica necesaria programada para permitir que diferentes tareas ramifiquen o ejecuten condicionalmente solo aquellas partes del programa que están diseñadas para ejecutar. Es decir, las tareas no necesariamente tienen que ejecutar el programa completo, tal vez solo una parte de él.\n",
    "\n",
    "El modelo SPMD, utilizando paso de mensajes o programación híbrida, es probablemente el modelo de programación paralela más comúnmente utilizado para clústeres multinodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439dd7c3",
   "metadata": {},
   "source": [
    "##### MPMD (Multiple Program Multiple Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100042f2",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel35.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- **PROGRAMAS MÚLTIPLES:** Las tareas pueden ejecutar diferentes programas simultáneamente. Los programas pueden ser de hilos, paso de mensajes, paralelismo de datos o híbrido.\n",
    "- **DATOS MÚLTIPLES:** Todas las tareas pueden utilizar diferentes datos.\n",
    "\n",
    "Las aplicaciones MPMD no son tan comunes como las aplicaciones SPMD, pero pueden ser más adecuadas para ciertos tipos de problemas, particularmente aquellos que se prestan mejor a la descomposición funcional que a la descomposición por dominios (esto se discutirá más adelante bajo el tema de Particionamiento).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934d956",
   "metadata": {},
   "source": [
    "##### Comparación y Uso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae764ab",
   "metadata": {},
   "source": [
    "**Ventajas de SPMD:**\n",
    "- **Eficiencia en el Manejo de Recursos:** Al ejecutar el mismo programa, la optimización y el manejo del código pueden ser más directos y eficientes.\n",
    "- **Simplificación del Desarrollo:** Menos variedad en los programas reduce la complejidad durante el desarrollo y la depuración.\n",
    "\n",
    "**Ventajas de MPMD:**\n",
    "- **Flexibilidad en la Ejecución:** Permite que diferentes nodos o grupos de nodos ejecuten diferentes programas según sea necesario, lo cual es útil para problemas heterogéneos.\n",
    "- **Adaptabilidad a Problemas Complejos:** Ideal para aplicaciones que necesitan diferentes funcionalidades en diferentes partes del proceso de cálculo.\n",
    "\n",
    "Ambos modelos ofrecen enfoques poderosos para la programación paralela y se eligen según los requisitos específicos y la naturaleza de los problemas a resolver."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4299db",
   "metadata": {},
   "source": [
    "## Diseño de Programas Paralelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd3e33",
   "metadata": {},
   "source": [
    "### Paralelización Automática vs. Manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaba9d4",
   "metadata": {},
   "source": [
    "El diseño y desarrollo de programas paralelos ha sido tradicionalmente un proceso muy manual. Generalmente, el programador es responsable tanto de identificar como de implementar el paralelismo.\n",
    "\n",
    "Desarrollar códigos paralelos manualmente es a menudo un proceso que consume tiempo, es complejo, propenso a errores y requiere iteraciones.\n",
    "\n",
    "Durante varios años, han estado disponibles diversas herramientas para asistir al programador en la conversión de programas seriales a programas paralelos. El tipo de herramienta más común utilizado para paralelizar automáticamente un programa serial es un compilador paralelizante o un preprocesador.\n",
    "\n",
    "Un compilador paralelizante generalmente funciona de dos maneras diferentes:\n",
    "\n",
    "\n",
    "***Completamente Automático***\n",
    "- El compilador analiza el código fuente e identifica oportunidades para el paralelismo.\n",
    "- El análisis incluye la identificación de inhibidores del paralelismo y posiblemente una ponderación de costos sobre si el paralelismo realmente mejoraría el rendimiento.\n",
    "- Los bucles (do, for) son el objetivo más frecuente para la paralelización automática.\n",
    "\n",
    "***Dirigido por el Programador***\n",
    "- Utilizando \"directivas de compilador\" o posiblemente banderas de compilador, el programador le indica explícitamente al compilador cómo paralelizar el código.\n",
    "- Puede ser usado en conjunto con algún grado de paralelización automática también.\n",
    "\n",
    "La paralelización generada por el compilador más común se realiza usando memoria compartida en el nodo y hilos (como OpenMP).\n",
    "\n",
    "Si estás comenzando con un código serial existente y tienes restricciones de tiempo o presupuesto, entonces la paralelización automática puede ser la respuesta. Sin embargo, hay varias advertencias importantes que se aplican a la paralelización automática:\n",
    "\n",
    "- Puede producir resultados incorrectos.\n",
    "- El rendimiento puede degradarse.\n",
    "- Es mucho menos flexible que la paralelización manual.\n",
    "- Limitada a un subconjunto (principalmente bucles) del código.\n",
    "- Puede que no paralelice el código si el análisis del compilador sugiere que hay inhibidores o el código es demasiado complejo.\n",
    "\n",
    "El resto de esta sección se aplica al método manual de desarrollo de códigos paralelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f789d2",
   "metadata": {},
   "source": [
    "### Comprender el Problema y el Programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68866f78",
   "metadata": {},
   "source": [
    "$$\\text{Programas = algoritmos + datos + (hardware)}$$\n",
    "\n",
    "Sin duda, el primer paso en el desarrollo de software paralelo es primero comprender el problema que deseas resolver en paralelo. Si estás comenzando con un programa serial, esto significa entender también el código existente.\n",
    "Antes de dedicar tiempo en un intento de desarrollar una solución paralela para un problema, determina si el problema es uno que realmente se pueda paralelizar.\n",
    "\n",
    "- **Ejemplo de un problema fácil de paralelizar:** Calcular la energía potencial para cada una de varias miles de conformaciones independientes de una molécula. Una vez hecho esto, encontrar la conformación de energía mínima. Este problema puede resolverse en paralelo. Cada una de las conformaciones moleculares es determinable independientemente. El cálculo de la conformación de energía mínima también es un problema paralelizable.\n",
    "\n",
    "- **Ejemplo de un problema y algoritmo con poco o ningún paralelismo:** Cálculo de los primeros $10,000$ miembros de la serie de Fibonacci $(0,1,1,2,3,5,8,13,21, \\ldots)$ mediante el uso de la fórmula:\n",
    "\n",
    "$$F(n) = F(n-1) + F(n-2)$$\n",
    "\n",
    "El cálculo del valor de $F(n)$ utiliza los de $F(n-1)$ y $F(n-2)$, que deben ser calculados primero.\n",
    "\n",
    "Un ejemplo de un algoritmo paralelo para resolver este problema (usando la fórmula de Binet):\n",
    "\n",
    "$$F_n = \\frac{\\varphi^n - (-\\varphi)^{-n}}{\\sqrt{5}} = \\frac{\\varphi^n - (-\\varphi)^{-n}}{2\\varphi - 1} $$\n",
    "\n",
    "  donde\n",
    "\n",
    "$$\\varphi = \\frac{1 + \\sqrt{5}}{2} \\approx 1.6180339887 \\ldots $$\n",
    "\n",
    "- **Identificar los puntos críticos del programa:**  \n",
    "  - Conoce dónde se está realizando la mayor parte del trabajo real. La mayoría de los programas científicos y técnicos generalmente realizan la mayor parte de su trabajo en pocos lugares.\n",
    "  - Los perfiles y herramientas de análisis de rendimiento pueden ayudar aquí.\n",
    "  - Concéntrate en paralelizar los puntos críticos e ignora aquellas secciones del programa que representan poco uso de CPU.\n",
    "\n",
    "- **Identificar cuellos de botella en el programa:**  \n",
    "  - ¿Hay áreas que son desproporcionadamente lentas o causan que el trabajo paralelizable se detenga o se posponga? Por ejemplo, las operaciones de I/O generalmente ralentizan un programa.\n",
    "  - Puede ser posible reestructurar el programa o usar un algoritmo diferente para reducir o eliminar áreas lentas innecesarias.\n",
    "\n",
    "- **Identificar inhibidores al paralelismo.** Una clase común de inhibidor es la dependencia de datos, como se demostró con la secuencia de Fibonacci anterior.  \n",
    "  - Investiga otros algoritmos si es posible. Esto puede ser la consideración más importante al diseñar una aplicación paralela.\n",
    "  - Aprovecha el software paralelo de terceros optimizado y las bibliotecas matemáticas altamente optimizadas disponibles de proveedores líderes (ESSL de IBM, MKL de Intel, AMCL de AMD, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9685f3",
   "metadata": {},
   "source": [
    "### Particionamiento en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3d17e8",
   "metadata": {},
   "source": [
    "El particionamiento es uno de los primeros pasos en el diseño de un programa paralelo y consiste en dividir el problema en \"trozos\" discretos de trabajo que pueden ser distribuidos a múltiples tareas. Este proceso es conocido como descomposición o particionamiento y es fundamental para la eficiencia y efectividad de las soluciones paralelas. Existen dos formas básicas de particionar el trabajo computacional entre las tareas paralelas: la descomposición de dominio y la descomposición funcional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2053db",
   "metadata": {},
   "source": [
    "#### Descomposición de Dominio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405e046",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel36.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "En este tipo de particionamiento, los datos asociados con un problema son descompuestos. Cada tarea paralela entonces trabaja en una porción de los datos. \n",
    "\n",
    "**Maneras de particionar datos:**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel37.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- **Por Bloques:** Los datos se dividen en bloques contiguos, cada uno asignado a una tarea diferente. Esto es común en problemas donde los datos se pueden segmentar naturalmente, como en simulaciones espaciales o temporales.\n",
    "  \n",
    "- **Por Ciclos:** Los datos se distribuyen en un patrón cíclico entre las tareas, lo que puede ayudar a balancear la carga de trabajo cuando las operaciones realizadas sobre los datos varían en complejidad.\n",
    "  \n",
    "- **Por Dispersión:** Los datos se dividen de manera que cada tarea recibe fragmentos que están dispersos a través del conjunto de datos completo. Esto puede ser útil en situaciones donde la interacción entre elementos de datos es compleja y no se limita a áreas contiguas.\n",
    "\n",
    "La descomposición de dominio es especialmente útil en problemas que se basan en la manipulación de grandes volúmenes de datos, como en el procesamiento de imágenes, simulaciones de fluidos, y análisis de grandes conjuntos de datos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836992c9",
   "metadata": {},
   "source": [
    "#### Descomposición Funcional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a901fc8",
   "metadata": {},
   "source": [
    "En este enfoque, el foco está en la computación que debe ser realizada más que en los datos manipulados por la computación. El problema se descompone según el trabajo que debe realizarse. Cada tarea realiza entonces una porción del trabajo general.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel38.gif?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "**Características de la descomposición funcional:**\n",
    "- **División por Tareas:** El problema se divide en diferentes funciones o tareas específicas, cada una realizada por diferentes procesos o hilos.\n",
    "  \n",
    "- **Especialización:** Cada tarea paralela se especializa en una función particular, lo cual puede llevar a una mayor eficiencia en tareas que requieren habilidades o recursos específicos.\n",
    "  \n",
    "- **Independencia:** Las tareas son a menudo independientes o tienen interdependencias mínimas, lo que reduce la necesidad de sincronización y comunicación entre tareas.\n",
    "\n",
    "La descomposición funcional se presta bien a problemas que pueden ser divididos en diferentes tareas que son relativamente independientes y pueden ser ejecutadas concurrentemente, como en sistemas de manejo de transacciones, donde diferentes tareas pueden manejar diferentes aspectos de un proceso de negocio.\n",
    "\n",
    "El éxito del particionamiento en programación paralela depende en gran medida de la naturaleza del problema y de cómo se descomponen los datos o las funciones. Una buena estrategia de particionamiento maximiza la eficiencia del paralelismo minimizando la comunicación necesaria entre tareas y equilibrando la carga de trabajo entre los procesadores. Identificar el tipo adecuado de particionamiento es crucial y puede variar significativamente de un problema a otro, influenciado por los objetivos de rendimiento y las características específicas del sistema computacional utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1b157e",
   "metadata": {},
   "source": [
    "### Comunicaciones en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b69303",
   "metadata": {},
   "source": [
    "#### ¿Quién necesita comunicaciones?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848442f",
   "metadata": {},
   "source": [
    "La necesidad de comunicación entre tareas depende del problema:\n",
    "\n",
    "**No Necesitas Comunicaciones**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel42.gif?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "- Algunos tipos de problemas pueden descomponerse y ejecutarse en paralelo sin apenas necesidad de que las tareas compartan datos. A estos problemas se les suele llamar paralelos embarazosamente - requieren poca o ninguna comunicación.\n",
    "- **Ejemplo:** Imagina una operación de procesamiento de imagen donde cada píxel en una imagen en blanco y negro necesita invertir su color. Los datos de la imagen se pueden distribuir fácilmente a múltiples tareas que actúan independientemente unas de otras para realizar su parte del trabajo.\n",
    "\n",
    "**Necesitas Comunicaciones**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel43.gif?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "- La mayoría de las aplicaciones paralelas no son tan simples y sí requieren que las tareas compartan datos entre sí.\n",
    "- **Ejemplo:** Un problema de difusión de calor en 2-D requiere que una tarea conozca las temperaturas calculadas por las tareas que tienen datos adyacentes. Los cambios en los datos vecinos tienen un efecto directo en los datos de la tarea.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8230e982",
   "metadata": {},
   "source": [
    "#### Factores a Considerar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf180638",
   "metadata": {},
   "source": [
    "Hay varios factores importantes a considerar al diseñar las comunicaciones inter-tareas de tu programa:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f886ac1",
   "metadata": {},
   "source": [
    "**Sobrecarga de Comunicación (overhead)**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel44.jpeg?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "- La comunicación inter-tareas casi siempre implica sobrecarga.\n",
    "- Ciclos de máquina y recursos que podrían usarse para la computación se usan en cambio para empaquetar y transmitir datos.\n",
    "- Las comunicaciones frecuentemente requieren algún tipo de sincronización entre tareas, lo que puede resultar en que las tareas pasen tiempo \"esperando\" en lugar de trabajar.\n",
    "- El tráfico de comunicación competidor puede saturar el ancho de banda de red disponible, agravando aún más los problemas de rendimiento.\n",
    "\n",
    "**Latencia vs. Ancho de Banda**\n",
    "- **Latencia:** Es el tiempo que tarda en enviarse un mensaje mínimo (de 0 bytes) de un punto A a un punto B. Comúnmente expresada en microsegundos.\n",
    "- **Ancho de Banda:** Es la cantidad de datos que se pueden comunicar por unidad de tiempo. Comúnmente expresado en megabytes/seg o gigabytes/seg.\n",
    "- Enviar muchos mensajes pequeños puede causar que la latencia domine las sobrecargas de comunicación. A menudo es más eficiente empaquetar mensajes pequeños en un mensaje más grande, aumentando así el ancho de banda efectivo de las comunicaciones.\n",
    "\n",
    "**Visibilidad de las Comunicaciones**\n",
    "- En el **Modelo de Paso de Mensajes**, las comunicaciones son explícitas y generalmente bastante visibles y bajo el control del programador.\n",
    "- En el **Modelo de Paralelismo de Datos**, las comunicaciones a menudo ocurren de manera transparente para el programador, especialmente en arquitecturas de memoria distribuida. El programador puede no saber exactamente cómo se están realizando las comunicaciones inter-tareas.\n",
    "\n",
    "**Comunicaciones Sincrónicas vs. Asincrónicas**\n",
    "- **Sincrónicas:** Requieren algún tipo de \"apretón de manos\" entre tareas que comparten datos. Esto puede estar explícitamente estructurado en el código por el programador.\n",
    "- **Asincrónicas:** Permiten que las tareas transfieran datos independientemente una de otra. Por ejemplo, la tarea 1 puede preparar y enviar un mensaje a la tarea 2 y luego comenzar inmediatamente a realizar otro trabajo.\n",
    "\n",
    "**Ámbito de las Comunicaciones**\n",
    "\n",
    "- Saber qué tareas deben comunicarse entre sí es crítico durante la etapa de diseño de un código paralelo. Ambos ámbitos descritos a continuación pueden implementarse de manera sincrónica o asincrónica.\n",
    "  - **Punto a Punto:** Involucra dos tareas con una tarea actuando como el emisor/productor de datos, y la otra como el receptor/consumidor.\n",
    "  - **Colectiva:** Involucra el intercambio de datos entre más de dos tareas, que a menudo se especifican como miembros de un grupo común o colectivo.\n",
    "  \n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel45.PNG?raw=true\" width=\"450\" />\n",
    "</p>\n",
    "\n",
    "La imagen muestra cuatro patrones de comunicación comunes en la programación paralela y el procesamiento distribuido: broadcast, scatter, gather y reduction. Estos patrones son fundamentales en la implementación eficiente de algoritmos paralelos para la distribución y recopilación de datos, así como para la combinación de resultados.\n",
    "\n",
    "- ***[Broadcast](https://www.cs.utexas.edu/users/AustinVilla/legged/papers/BroadcastProgrammingModels.pdf) (Difusión o Transmisión):*** Implica la distribución de datos desde un solo proceso (a menudo denominado el \"root\") a todos los demás procesos en un grupo. En un contexto de MPI (Message Passing Interface), por ejemplo, un valor o un conjunto de valores se envía desde un proceso fuente a todos los procesos dentro de un comunicador. Es útil cuando todos los procesos necesitan una copia idéntica de ciertos datos para realizar cálculos paralelos, como una constante necesaria para cálculos o una semilla para generadores de números aleatorios.\n",
    "\n",
    "- ***[Scatter](https://www.gaurgaurav.com/patterns/scatter-gather/) (Dispersión o Distribución):*** Es un patrón donde el proceso root reparte segmentos diferentes y generalmente no superpuestos de un arreglo de datos a cada uno de los procesos en el grupo, incluido él mismo si es necesario. Este patrón es efectivo cuando se distribuye un arreglo grande entre varios procesos para su procesamiento paralelo, donde cada proceso trabaja en una parte del arreglo.\n",
    "\n",
    "- ***Gather (Recolección o Agrupamiento):*** Es el proceso inverso a scatter. En lugar de distribuir datos, gather los colecta de todos los procesos en el grupo y los reúne en un único proceso root. Cada proceso envía su segmento de datos al proceso root, que luego los ensambla en un único conjunto de datos ordenado. Se utiliza a menudo al final de una operación paralela para recopilar resultados parciales de cada proceso y unirlos en un resultado final o para realizar un análisis posterior.\n",
    "\n",
    "- ***[Reduction](https://en.wikipedia.org/wiki/Reduction_operator) (Reducción):*** Es un patrón de comunicación que combina los elementos de los datos de todos los procesos en el grupo utilizando una operación especificada (como sumar, maximizar, minimizar) y pasa el resultado combinado a todos los procesos o solo al proceso root. Se utiliza comúnmente para operaciones como calcular la suma de los elementos generados por cada proceso, encontrar el máximo o mínimo valor, o cualquier otra operación de reducción que necesite ser aplicada sobre los datos distribuidos entre los procesos.\n",
    "\n",
    "En la imagen, los colores y las formas representan los datos específicos manejados por cada operación: broadcast muestra una pieza de información que se comparte desde un solo proceso a todos los demás; scatter muestra cómo se distribuye un conjunto de datos a diferentes procesos; gather representa la colecta de diferentes conjuntos de datos de vuelta al proceso root; y reduction ilustra cómo los datos de varios procesos se combinan en un solo resultado que puede ser repartido entre todos los procesos o acumulado en el proceso root.\n",
    "\n",
    "Cada uno de estos patrones es esencial en situaciones donde la coordinación y la eficiencia en la manipulación de datos son críticas para el rendimiento y la exactitud de los cálculos paralelos.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Eficiencia de las Comunicaciones**\n",
    "- A menudo, el programador tiene opciones que pueden afectar el rendimiento de las comunicaciones. Elegir una plataforma con una red más rápida puede ser una opción.\n",
    "\n",
    "**Sobrecarga y Complejidad**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel46.gif?raw=true\" width=\"450\" />\n",
    "</p>\n",
    "\n",
    "- Finalmente, ¡ten en cuenta que esta es solo una lista parcial de cosas a considerar!\n",
    "\n",
    "Entender estos factores y cómo influyen en las comunicaciones dentro de un programa paralelo es crucial para el diseño eficiente de software que maximice el rendimiento mientras minimiza los cuellos de botella y la sobrecarga."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4450ec",
   "metadata": {},
   "source": [
    "### Sincronización en Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9a9661",
   "metadata": {},
   "source": [
    "La gestión de la secuencia de trabajo y de las tareas que la realizan es una consideración de diseño crítica para la mayoría de los programas paralelos.\n",
    "\n",
    "- Puede ser un factor significativo en el rendimiento del programa (o la falta de él).\n",
    "- A menudo requiere \"serialización\" de segmentos del programa.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel47.jpeg?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691dad15",
   "metadata": {},
   "source": [
    "#### Tipos de Sincronización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6559f3d0",
   "metadata": {},
   "source": [
    "**Barrera (Barrier)**\n",
    "- Generalmente implica que todas las tareas están involucradas.\n",
    "- Cada tarea ejecuta su trabajo hasta que alcanza la barrera. Entonces se detiene o \"bloquea\".\n",
    "- Cuando la última tarea alcanza la barrera, todas las tareas se sincronizan.\n",
    "- Lo que sucede a partir de aquí varía. A menudo, se debe hacer una sección de trabajo serial. En otros casos, las tareas se liberan automáticamente para continuar su trabajo.\n",
    "\n",
    "**Bloqueo / Semáforo (Lock / Semaphore)**\n",
    "- Puede involucrar a cualquier número de tareas.\n",
    "- Típicamente usado para serializar (proteger) el acceso a datos globales o una sección de código. Solo una tarea a la vez puede usar (poseer) el bloqueo / semáforo / bandera.\n",
    "- La primera tarea en adquirir el bloqueo lo \"establece\". Esta tarea puede entonces acceder de manera segura (serial) a los datos o código protegidos.\n",
    "- Otras tareas pueden intentar adquirir el bloqueo pero deben esperar hasta que la tarea que posee el bloqueo lo libere.\n",
    "- Puede ser bloqueante o no bloqueante.\n",
    "\n",
    "**Operaciones de Comunicación Sincrónicas**\n",
    "- Involucra solo a aquellas tareas que ejecutan una operación de comunicación.\n",
    "- Cuando una tarea realiza una operación de comunicación, se requiere alguna forma de coordinación con las otras tarea(s) que participan en la comunicación. Por ejemplo, antes de que una tarea pueda realizar una operación de envío, primero debe recibir una confirmación de la tarea receptora de que está bien enviar.\n",
    "- Discutido previamente en la sección de Comunicaciones.\n",
    "\n",
    "***Consideraciones Adicionales***\n",
    "\n",
    "- **Interbloqueo (Deadlock):** Ocurre cuando dos o más tareas esperan indefinidamente por recursos o eventos que están siendo bloqueados por las otras tareas.\n",
    "- **Inanición (Starvation):** Una tarea nunca adquiere el acceso necesario a los recursos debido a que otros procesos están continuamente siendo preferidos.\n",
    "- **Coordinación de Tareas:** Implica gestionar el orden y el tiempo en el que varias tareas acceden a recursos compartidos para evitar inconsistencias y errores.\n",
    "\n",
    "La sincronización eficiente es crucial para asegurar la integridad de los datos y el comportamiento correcto de un programa paralelo. Sin embargo, también puede ser una fuente de reducción de rendimiento si no se implementa cuidadosamente, ya que puede aumentar el tiempo de inactividad de las tareas y limitar la concurrencia. La elección entre diferentes mecanismos de sincronización dependerá del problema específico, el modelo de programación paralela y las características de la arquitectura de hardware en uso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7576900b",
   "metadata": {},
   "source": [
    "### Dependencias de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296e1673",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c4551",
   "metadata": {},
   "source": [
    "Una dependencia existe entre instrucciones de un programa cuando el orden de ejecución de las instrucciones afecta los resultados del programa.\n",
    "Una dependencia de datos resulta del uso múltiple de la misma ubicación(es) de almacenamiento por diferentes tareas.\n",
    "Las dependencias son importantes en la programación paralela porque son uno de los principales inhibidores del paralelismo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel48.jpeg?raw=true\" width=\"200\" />\n",
    "</p>\n",
    "\n",
    "Veamos algunos ejemplos:\n",
    "\n",
    "**Dependencia de Datos Llevada por Bucle (Loop Carried Data Dependence):**\n",
    "```fortran\n",
    "DO J = MYSTART,MYEND\n",
    "   A(J) = A(J-1) * 2.0\n",
    "END DO\n",
    "```\n",
    "El valor de `A(J-1)` debe ser computado antes del valor de `A(J)`, por lo tanto, `A(J)` exhibe una dependencia de datos en `A(J-1)`. El paralelismo está inhibido.\n",
    "Si la Tarea 2 tiene `A(J)` y la tarea 1 tiene `A(J-1)`, para calcular el valor correcto de `A(J)` es necesario:\n",
    "- En arquitecturas de memoria distribuida - la tarea 2 debe obtener el valor de `A(J-1)` de la tarea 1 después de que esta termine su cálculo.\n",
    "- En arquitecturas de memoria compartida - la tarea 2 debe leer `A(J-1)` después de que la tarea 1 lo actualice.\n",
    "\n",
    "**Dependencia de Datos Independiente de Bucle (Loop Independent Data Dependence):**\n",
    "```plaintext\n",
    "tarea 1        tarea 2\n",
    "------        ------\n",
    "X = 2         X = 4\n",
    "  .             .\n",
    "  .             .\n",
    "Y = X**2      Y = X**3\n",
    "```\n",
    "Al igual que con el ejemplo anterior, el paralelismo está inhibido. El valor de `Y` depende de:\n",
    "- En arquitecturas de memoria distribuida - si o cuándo el valor de `X` se comunica entre las tareas.\n",
    "- En arquitecturas de memoria compartida - qué tarea almacena el valor de `X` por última vez.\n",
    "\n",
    "Aunque todas las dependencias de datos son importantes de identificar al diseñar programas paralelos, las dependencias llevadas por bucle son particularmente importantes ya que los bucles son posiblemente el objetivo más común de los esfuerzos de paralelización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984761bc",
   "metadata": {},
   "source": [
    "#### Cómo Manejar las Dependencias de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ff94a1",
   "metadata": {},
   "source": [
    "- En arquitecturas de memoria distribuida - comunicar los datos requeridos en puntos de sincronización.\n",
    "- En arquitecturas de memoria compartida - sincronizar las operaciones de lectura/escritura entre tareas.\n",
    "\n",
    "Manejar las dependencias de datos requiere una comprensión profunda de cómo el flujo de datos y el control afectan el paralelismo potencial. Las optimizaciones pueden incluir reestructurar algoritmos para minimizar las dependencias o implementar mecanismos para gestionarlas de forma efectiva, lo que puede incluir sincronización cuidadosa y uso estratégico de recursos de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8fee82",
   "metadata": {},
   "source": [
    "### Balanceo de Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa79f848",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel49.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "El balanceo de carga se refiere a la práctica de distribuir cantidades aproximadamente iguales de trabajo entre las tareas para que todas estén ocupadas todo el tiempo. Puede considerarse una minimización del tiempo de inactividad de las tareas.\n",
    "\n",
    "El balanceo de carga es importante para los programas paralelos por razones de rendimiento. Por ejemplo, si todas las tareas están sujetas a un punto de sincronización de barrera, la tarea más lenta determinará el rendimiento general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6031512f",
   "metadata": {},
   "source": [
    "#### Cómo Lograr el Balance de Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b613b",
   "metadata": {},
   "source": [
    "**Particionar Equitativamente el Trabajo que Recibe Cada Tarea**\n",
    "- Para operaciones de arreglo/matriz donde cada tarea realiza un trabajo similar, distribuye de manera uniforme el conjunto de datos entre las tareas.\n",
    "- Para iteraciones de bucle donde el trabajo realizado en cada iteración es similar, distribuye las iteraciones de manera uniforme entre las tareas.\n",
    "- Si se utiliza una mezcla heterogénea de máquinas con características de rendimiento variables, asegúrate de usar alguna herramienta de análisis de rendimiento para detectar cualquier desequilibrio de carga y ajusta el trabajo en consecuencia.\n",
    "\n",
    "**Usar Asignación Dinámica de Trabajo**\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel50.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "Ciertas clases de problemas resultan en desequilibrios de carga incluso si los datos están distribuidos uniformemente entre las tareas:\n",
    "\n",
    "- Cuando la cantidad de trabajo que realizará cada tarea es intencionalmente variable, o no se puede predecir, puede ser útil utilizar un enfoque de grupo de tareas con programador. A medida que cada tarea termina su trabajo, recibe una nueva pieza de la cola de trabajo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel51.gif?raw=true\" width=\"400\" />\n",
    "</p>\n",
    "\n",
    "Finalmente, puede ser necesario diseñar un algoritmo que detecte y maneje desequilibrios de carga a medida que ocurren dinámicamente dentro del código. Esto puede significar ajustes en tiempo real durante la ejecución del programa para reasignar el trabajo de las tareas más ocupadas a las menos ocupadas, a fin de optimizar el uso de los recursos y mejorar el rendimiento general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2982c446",
   "metadata": {},
   "source": [
    "### Granularidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c40ba",
   "metadata": {},
   "source": [
    "#### Razón de Cálculo / Comunicación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb83b1",
   "metadata": {},
   "source": [
    "En la computación paralela, la granularidad es una medida cualitativa de la relación entre el cálculo y la comunicación.\n",
    "Los períodos de cálculo están típicamente separados de los períodos de comunicación por eventos de sincronización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163d7fa6",
   "metadata": {},
   "source": [
    "#### Paralelismo de Grano Fino (Fine-grain Parallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4b02e",
   "metadata": {},
   "source": [
    "- Se realizan cantidades relativamente pequeñas de trabajo computacional entre eventos de comunicación.\n",
    "- Baja relación de cálculo a comunicación.\n",
    "- Facilita el balanceo de carga.\n",
    "- Implica alta sobrecarga de comunicación y menos oportunidades para el aumento de rendimiento.\n",
    "- Si la granularidad es demasiado fina, es posible que la sobrecarga requerida para las comunicaciones y sincronización entre tareas tome más tiempo que el cálculo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel52.gif?raw=true\" width=\"200\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b4b08",
   "metadata": {},
   "source": [
    "#### Paralelismo de Grano Grueso (Coarse-grain Parallelism)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c58cde",
   "metadata": {},
   "source": [
    "- Se realizan cantidades relativamente grandes de trabajo computacional entre eventos de comunicación/sincronización.\n",
    "- Alta relación de cálculo a comunicación.\n",
    "- Implica más oportunidades para el aumento de rendimiento.\n",
    "- Más difícil de balancear la carga de manera eficiente.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel53.gif?raw=true\" width=\"200\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286aebe",
   "metadata": {},
   "source": [
    "#### ¿Cuál es Mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646b041",
   "metadata": {},
   "source": [
    "La granularidad más eficiente depende del algoritmo y del entorno de hardware en el que se ejecuta.\n",
    "- En la mayoría de los casos, la sobrecarga asociada con las comunicaciones y la sincronización es alta en relación con la velocidad de ejecución, por lo que es ventajoso tener una granularidad gruesa.\n",
    "- El paralelismo de grano fino puede ayudar a reducir las sobrecargas debido al desequilibrio de carga.\n",
    "\n",
    "En la práctica, la elección entre granularidad fina y gruesa a menudo requiere un equilibrio entre la sobrecarga de gestión de las tareas paralelas y la eficiencia con la que se pueden realizar los cálculos. Los algoritmos y aplicaciones específicos pueden requerir sintonía fina y ajustes iterativos para encontrar el nivel de granularidad óptimo que maximice el rendimiento dado un conjunto particular de restricciones de cómputo y comunicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23caf2",
   "metadata": {},
   "source": [
    "### I/O en Computación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92610393",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel54.gif?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435d885",
   "metadata": {},
   "source": [
    "#### Las Malas Noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b7c9f2",
   "metadata": {},
   "source": [
    "**Jerarquía de Memoria y Operaciones de I/O**\n",
    "- Las operaciones de I/O (entrada/salida) son generalmente consideradas como inhibidores del paralelismo.\n",
    "- Las operaciones de I/O requieren órdenes de magnitud más tiempo que las operaciones de memoria.\n",
    "- Los sistemas de I/O paralelo pueden ser inmaduros o no estar disponibles para todas las plataformas.\n",
    "- En un entorno donde todas las tareas ven el mismo espacio de archivo, las operaciones de escritura pueden resultar en la sobreescritura de archivos.\n",
    "- Las operaciones de lectura pueden verse afectadas por la capacidad del servidor de archivos para manejar múltiples solicitudes de lectura al mismo tiempo.\n",
    "- I/O que debe realizarse a través de la red (NFS, no local) puede causar cuellos de botella severos e incluso colapsar servidores de archivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdc0a68",
   "metadata": {},
   "source": [
    "#### Las Buenas Noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00317a1",
   "metadata": {},
   "source": [
    "**Sistemas de Archivos Paralelos**\n",
    "- Están disponibles sistemas de archivos paralelos. Por ejemplo:\n",
    "  - GPFS: General Parallel File System (IBM), ahora llamado IBM Spectrum Scale.\n",
    "  - Lustre: para clústeres de Linux (Intel)\n",
    "  - HDFS: Hadoop Distributed File System (Apache)\n",
    "  - PanFS: Panasas ActiveScale File System para clústeres de Linux (Panasas, Inc.)\n",
    "  - Y más - ver [Lista de sistemas de archivos paralelos distribuidos en Wikipedia](http://en.wikipedia.org/wiki/List_of_file_systems#Distributed_parallel_file_systems)\n",
    "\n",
    "La especificación de la interfaz de programación de I/O paralelo para MPI ha estado disponible desde 1996 como parte de MPI-2. Las implementaciones de proveedores y gratuitas ahora son comúnmente disponibles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e29be52",
   "metadata": {},
   "source": [
    "#### Algunas Sugerencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325b2629",
   "metadata": {},
   "source": [
    "- **Regla #1:** Reducir el I/O total tanto como sea posible.\n",
    "- Si tienes acceso a un sistema de archivos paralelo, úsalo.\n",
    "- Escribir grandes bloques de datos en lugar de pequeños suele ser significativamente más eficiente.\n",
    "- Un menor número de archivos grandes rinde mejor que muchos archivos pequeños.\n",
    "- Confinar las operaciones de I/O a porciones seriales específicas del trabajo, y luego usar comunicaciones paralelas para distribuir datos a tareas paralelas. Por ejemplo, la Tarea 1 podría leer un archivo de entrada y luego comunicar los datos necesarios a otras tareas. Del mismo modo, la Tarea 1 podría realizar operaciones de escritura después de recibir los datos necesarios de todas las demás tareas.\n",
    "- Agregar operaciones de I/O entre tareas: en lugar de que muchas tareas realicen I/O, tener un subconjunto de tareas que lo hagan.\n",
    "\n",
    "En resumen, una estrategia eficaz de I/O en entornos de computación paralela puede tener un impacto significativo en el rendimiento general de una aplicación. Optimizar las operaciones de I/O para reducir la sobrecarga y evitar cuellos de botella es esencial para aprovechar al máximo los recursos de computación paralela."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be73f4e2",
   "metadata": {},
   "source": [
    "### Depuración (Debugging)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9784b759",
   "metadata": {},
   "source": [
    "#### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3b457",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel55.gif?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "La depuración de códigos paralelos puede ser increíblemente difícil, particularmente a medida que los códigos se escalan.\n",
    "\n",
    "La buena noticia es que hay excelentes depuradores disponibles para ayudar:\n",
    "- **Hilos (Threaded):** pthreads y OpenMP\n",
    "- **MPI**\n",
    "- **GPU / aceleradores**\n",
    "- **Híbrido**\n",
    "\n",
    "Los usuarios de Livermore Computing tienen acceso a varias herramientas de depuración paralela instaladas en los clústeres de LC:\n",
    "- **TotalView** de RogueWave Software\n",
    "- **DDT** de Allinea\n",
    "- **Inspector** de Intel\n",
    "- **Stack Trace Analysis Tool (STAT):** desarrollado localmente en LLNL\n",
    "\n",
    "Todas estas herramientas tienen una curva de aprendizaje asociada con ellas.\n",
    "\n",
    "Para detalles e información para comenzar, ver:\n",
    "- Páginas web de LC en [hpc.llnl.gov/software/development-environment-software](https://hpc.llnl.gov/software/development-environment-software)\n",
    "- Tutorial de TotalView: [hpc.llnl.gov/documentation/tutorials/totalview-tutorial](https://hpc.llnl.gov/documentation/tutorials/totalview-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57ff5a",
   "metadata": {},
   "source": [
    "#### Consejos para la Depuración de Códigos Paralelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360b770",
   "metadata": {},
   "source": [
    "1. **Comenzar Pequeño:** Comienza con una versión reducida del problema para simplificar la detección de errores.\n",
    "2. **Aumentar Gradualmente:** Aumenta el tamaño y la complejidad del código de forma gradual, depurando a cada paso.\n",
    "3. **Utilizar Asertos:** Usa asertos y cheques de coherencia de datos para validar el estado del programa en puntos críticos.\n",
    "4. **Comunicación y Sincronización:** Presta especial atención a la comunicación y sincronización entre tareas, ya que estos son puntos comunes donde pueden surgir problemas.\n",
    "5. **Utilizar Herramientas Especializadas:** Aprovecha las herramientas de depuración paralela, que pueden ofrecer capacidades de detección de patrones de bloqueo, carreras de datos y otros problemas de concurrencia.\n",
    "6. **Registros Verbosos:** Mantén registros detallados de las ejecuciones del programa para rastrear y reproducir errores.\n",
    "7. **Pruebas Unitarias y de Integración:** Implementa pruebas unitarias y de integración para verificar el funcionamiento correcto de componentes individuales y su integración.\n",
    "\n",
    "La depuración en el contexto de la computación paralela es a menudo más arte que ciencia, y requiere una combinación de herramientas adecuadas, técnicas sistemáticas y a veces, una buena dosis de paciencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fd081",
   "metadata": {},
   "source": [
    "### Análisis de Rendimiento y Ajuste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66b534",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel56.jpeg?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Al igual que con la depuración, analizar y ajustar el rendimiento de programas paralelos puede ser mucho más desafiante que para programas seriales.\n",
    "\n",
    "Afortunadamente, existen varias herramientas excelentes para el análisis de rendimiento y el ajuste de programas paralelos.\n",
    "\n",
    "Los usuarios de Livermore Computing tienen acceso a varias de estas herramientas, la mayoría de las cuales están disponibles en todos los clústeres de producción.\n",
    "\n",
    "Algunos puntos de partida para herramientas instaladas en sistemas de LC:\n",
    "- Páginas web de LC: [hpc.llnl.gov/software/development-environment-software](https://hpc.llnl.gov/software/development-environment-software)\n",
    "- TAU (Tuning and Analysis Utilities): [Página de TAU](http://www.cs.uoregon.edu/research/tau/docs.php)\n",
    "- HPCToolkit: [Documentación de HPCToolkit](http://hpctoolkit.org/documentation.html)\n",
    "- Open|Speedshop: [Sitio de Open|Speedshop](https://www.openspeedshop.org/)\n",
    "- Vampir / Vampirtrace: [Sitio de Vampir](http://vampir.eu/)\n",
    "- Valgrind: [Sitio de Valgrind](http://valgrind.org/)\n",
    "- PAPI (Performance Application Programming Interface): [Sitio de PAPI](http://icl.cs.utk.edu/papi/)\n",
    "- mpiP: [Sitio de mpiP](http://mpip.sourceforge.net/)\n",
    "- memP: [Sitio de memP](http://memp.sourceforge.net/)\n",
    "\n",
    "***Consejos para el Análisis de Rendimiento y Ajuste:***\n",
    "\n",
    "1. **Identificar Cuellos de Botella:** Usa herramientas de perfilado para identificar dónde pasa la mayor parte del tiempo tu programa. Estos son a menudo los mejores candidatos para la optimización.\n",
    "\n",
    "2. **Evaluar la Paralelización:** Verifica que la carga de trabajo esté bien balanceada entre las tareas y que la sincronización y la comunicación no estén impactando negativamente el rendimiento.\n",
    "\n",
    "3. **Medir el Impacto de la Sincronización y la Comunicación:** Analiza cuánto tiempo se gasta en barreras de sincronización y en comunicación de datos entre procesos.\n",
    "\n",
    "4. **Optimizar el Uso de Memoria:** Asegúrate de que tu programa está utilizando la memoria de manera eficiente para evitar la contención y para que el acceso a la memoria no sea un cuello de botella.\n",
    "\n",
    "5. **Ajustar la Granularidad:** Si es necesario, ajusta la granularidad del paralelismo para mejorar el balance de carga y reducir la sobrecarga de comunicación.\n",
    "\n",
    "6. **Usar Contadores de Hardware:** Utiliza PAPI u otras interfaces para acceder a contadores de hardware y entender mejor el comportamiento de tu aplicación en relación con el hardware subyacente.\n",
    "\n",
    "7. **Revisar Algoritmos y Estructuras de Datos:** Considera la posibilidad de cambiar algoritmos y estructuras de datos por otros más eficientes o más adecuados para la computación paralela.\n",
    "\n",
    "8. **Iterar el Proceso:** El ajuste del rendimiento es un proceso iterativo. A menudo, una optimización llevará a la identificación de la siguiente área de mejora potencial.\n",
    "\n",
    "Analizar y ajustar el rendimiento es esencial para obtener el máximo provecho de los sistemas de cómputo paralelo. La integración de un análisis de rendimiento detallado y continuo en el ciclo de vida del desarrollo del software puede conducir a mejoras significativas en el rendimiento y la escalabilidad de los programas paralelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a60c2cf",
   "metadata": {},
   "source": [
    "## Ejemplos Paralelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a476fa",
   "metadata": {},
   "source": [
    "### Procesamiento de Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702704eb",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel57.gif?raw=true\" width=\"150\" />\n",
    "</p>\n",
    "\n",
    "Este ejemplo demuestra cálculos sobre elementos de un array bidimensional; se evalúa una función en cada elemento del array. La computación en cada elemento del array es independiente de otros elementos del array. El problema es intensivo computacionalmente.\n",
    "\n",
    "El programa serial calcula un elemento a la vez en orden secuencial. El código serial podría ser de la forma:\n",
    "\n",
    "```fortran\n",
    "do j = 1, n\n",
    "  do i = 1, n\n",
    "    a(i,j) = fcn(i,j)\n",
    "  end do\n",
    "end do\n",
    "```\n",
    "\n",
    "***Preguntas a considerar:***\n",
    "- ¿Este problema se puede paralelizar?\n",
    "- ¿Cómo se podría particionar el problema?\n",
    "- ¿Se necesitan comunicaciones?\n",
    "- ¿Hay dependencias de datos?\n",
    "- ¿Se necesitan sincronizaciones?\n",
    "- ¿Será una preocupación el balance de carga?\n",
    "\n",
    "***Solución Paralela 1: Procesamiento de Elementos de Array Distribuidos Uniformemente***\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img ccccsrc=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel58.gif?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "- El cálculo de los elementos es independiente uno de otro, lo que lleva a una solución paralela embarazosamente simple. \n",
    "- Los elementos del array están distribuidos uniformemente, de modo que cada proceso posee una porción del array (subarray).\n",
    "\n",
    "  - El esquema de distribución se elige para un acceso eficiente a la memoria; por ejemplo, paso unitario (stride de 1) a través de los subarrays. El paso unitario maximiza el uso de la caché/memoria.\n",
    "\n",
    "  - Dado que es deseable tener un paso unitario a través de los subarrays, la elección de un esquema de distribución depende del lenguaje de programación. Consulta el diagrama de Distribuciones Cíclicas por Bloques para ver las opciones.\n",
    "\n",
    "- El cálculo independiente de los elementos del array asegura que no es necesaria la comunicación o sincronización entre tareas.\n",
    "\n",
    "- Dado que la cantidad de trabajo está distribuida uniformemente entre los procesos, no deberían existir preocupaciones sobre el equilibrio de carga.\n",
    "\n",
    "- Después de que el array es distribuido, cada tarea ejecuta la porción del bucle correspondiente a los datos que posee.\n",
    "\n",
    "- Por ejemplo, se muestran tanto las distribuciones de bloques en Fortran (por columnas) como en C (por filas).\n",
    "\n",
    "\n",
    "**Distribución por Columnas (Fortran)**:\n",
    "```fortran\n",
    "do j = mystart, myend \n",
    "  do i = 1, n \n",
    "    a(i,j) = fcn(i,j) \n",
    "  end do \n",
    "end do\n",
    "```\n",
    "\n",
    "**Distribución por Filas (C)**:\n",
    "```c\n",
    "for (int i = mystart; i < myend; i++) { \n",
    "  for (int j = 0; j < n; j++) { \n",
    "    a[i][j] = fcn(i, j); \n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Observa que solo las variables del bucle externo son diferentes de la solución serial. \n",
    "\n",
    "***Una posible solución:***\n",
    "Implementar como un modelo de Programa Único Múltiples Datos (SPMD) - cada tarea ejecuta el mismo programa.\n",
    "- **Proceso Maestro:** Inicializa el array, envía información a los procesos trabajadores y recibe los resultados.\n",
    "- **Proceso Trabajador:** Recibe información, realiza su parte del cálculo y envía los resultados al maestro.\n",
    "Usando el esquema de almacenamiento de Fortran, realiza una distribución por bloques del array.\n",
    "\n",
    "***pseudocódigo:***\n",
    "\n",
    "Pseudo código  paralelo: se resaltan en rojo los cambios para el paralelismo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel61.PNG?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "***Solución Paralela 2: Grupo de Tareas***\n",
    "\n",
    "La solución anterior de array demostró un balanceo de carga estático:\n",
    "- Cada tarea tiene una cantidad fija de trabajo.\n",
    "- Puede haber tiempo de inactividad significativo para procesadores más rápidos o menos cargados; las tareas más lentas determinan el rendimiento general.\n",
    "\n",
    "Si tienes un problema de balanceo de carga (algunas tareas trabajan más rápido que otras), podrías beneficiarte de usar un esquema de \"grupo de tareas\".\n",
    "\n",
    "**Esquema de Grupo de Tareas**\n",
    "Dos procesos son empleados:\n",
    "- **Proceso Maestro:** Mantiene un grupo de tareas para que los procesos trabajadores las realicen, envía una tarea cuando se solicita, recopila resultados de los trabajadores.\n",
    "- **Proceso Trabajador:** Repetidamente hace lo siguiente:\n",
    "  - Obtiene tarea del proceso maestro.\n",
    "  - Realiza el cálculo.\n",
    "  - Envía los resultados al maestro.\n",
    "\n",
    "Los procesos trabajadores no saben antes de tiempo de ejecución qué parte del array manejarán o cuántas tareas realizarán. El balanceo de carga dinámico ocurre en tiempo de ejecución: las tareas más rápidas obtendrán más trabajo para hacer.\n",
    "\n",
    "Pseudo código  paralelo: se resaltan en rojo los cambios para el paralelismo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel62.PNG?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "\n",
    "\n",
    "En el ejemplo de grupo de tareas, cada tarea calculó un elemento individual del array como un trabajo. La relación de cálculo a comunicación es finamente granular. Las soluciones finamente granulares incurren en más sobrecarga de comunicación para reducir el tiempo de inactividad de las tareas. Una solución más óptima podría ser distribuir más trabajo con cada trabajo. La \"cantidad correcta\" de trabajo depende del problema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756e167d",
   "metadata": {},
   "source": [
    "### Cálculo de PI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46edd87c",
   "metadata": {},
   "source": [
    "#### Calcular PI de manera secuencial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a9c32",
   "metadata": {},
   "source": [
    "El valor de PI puede calcularse de varias maneras. Considere el método de Monte Carlo para aproximar PI:\n",
    "- Inscriba un círculo con radio $r$ en un cuadrado con longitud de lado de $2r$.\n",
    "- El área del círculo es $\\pi r^2$ y el área del cuadrado es $4r^2$.\n",
    "- La proporción del área del círculo respecto al área del cuadrado es:\n",
    "  $$\\pi r^2 / 4r^2 = \\pi / 4$$\n",
    "- Si genera aleatoriamente $N$ puntos dentro del cuadrado, aproximadamente $N \\pi / 4$ de esos puntos ($M$) deberían caer dentro del círculo.\n",
    "- $\\pi$ entonces se aproxima como:\n",
    "$$N \\pi / 4 = M$$\n",
    "$$\\pi / 4 = M / N$$\n",
    "$$\\pi = 4 M / N$$\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel59.gif?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "Note que aumentar el número de puntos generados mejora la aproximación.\n",
    "\n",
    "Pseudo código secuencial para este procedimiento:\n",
    "\n",
    "```pseudocode\n",
    "npoints = 10000\n",
    "circle_count = 0\n",
    "\n",
    "do j = 1,npoints\n",
    "  generate 2 random numbers between 0 and 1\n",
    "  xcoordinate = random1\n",
    "  ycoordinate = random2\n",
    "  if (xcoordinate, ycoordinate) inside circle\n",
    "  then circle_count = circle_count + 1\n",
    "end do\n",
    "\n",
    "PI = 4.0*circle_count/npoints\n",
    "```\n",
    "El problema es computacionalmente intensivo—la mayoría del tiempo se gasta ejecutando el bucle.\n",
    "\n",
    "***Preguntas para considerar:***\n",
    "- ¿Es este problema paralelizable?\n",
    "- ¿Cómo se dividiría el problema?\n",
    "- ¿Se necesitan comunicaciones?\n",
    "- ¿Hay dependencias de datos?\n",
    "- ¿Se necesitan sincronizaciones?\n",
    "- ¿Será una preocupación el balance de carga?\n",
    "\n",
    "***Solución Paralela***\n",
    "\n",
    "Otro problema que es fácil de paralelizar:\n",
    "- Todos los cálculos de puntos son independientes; no hay dependencias de datos.\n",
    "- El trabajo puede ser dividido equitativamente; no hay preocupaciones de balance de carga.\n",
    "- No se necesita comunicación ni sincronización entre tareas.\n",
    "\n",
    "Estrategia Paralela:\n",
    "- Divida el bucle en partes iguales que puedan ser ejecutadas por el grupo de tareas.\n",
    "- Cada tarea realiza de manera independiente su trabajo.\n",
    "- Se utiliza un modelo SPMD.\n",
    "- Una tarea actúa como maestro para recoger resultados y calcular el valor de PI.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel60.gif?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "Pseudo código  paralelo: se resaltan en rojo los cambios para el paralelismo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel63.PNG?raw=true\" width=\"350\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde33852",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "588.865px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
