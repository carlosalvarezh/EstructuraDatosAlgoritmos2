{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1b06738",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Estructura de Datos y Algoritmos II</h1>\n",
    "<h1 align=\"center\">Algoritmos Paralelos</h1>\n",
    "<h1 align=\"center\">2024</h1>\n",
    "<h1 align=\"center\">MEDELLÍN - COLOMBIA </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32776e",
   "metadata": {},
   "source": [
    "*** \n",
    "|[![Outlook](https://img.shields.io/badge/Microsoft_Outlook-0078D4?style=plastic&logo=microsoft-outlook&logoColor=white)](mailto:calvar52@eafit.edu.co)||[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/S09_AlgoritmosParalelos.ipynb)\n",
    "|-:|:-|--:|\n",
    "|[![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=plastic&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/carlosalvarez5/)|[![@alvarezhenao](https://img.shields.io/twitter/url/https/twitter.com/alvarezhenao.svg?style=social&label=Follow%20%40alvarezhenao)](https://twitter.com/alvarezhenao)|[![@carlosalvarezh](https://img.shields.io/badge/github-%23121011.svg?style=plastic&logo=github&logoColor=white)](https://github.com/carlosalvarezh)|\n",
    "\n",
    "<table>\n",
    " <tr align=left><td><img align=left src=\"https://github.com/carlosalvarezh/Curso_CEC_EAFIT/blob/main/images/CCLogoColorPop1.gif?raw=true\" width=\"25\">\n",
    " <td>Text provided under a Creative Commons Attribution license, CC-BY. All code is made available under the FSF-approved MIT license.(c) Carlos Alberto Alvarez Henao</td>\n",
    "</table>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f6488c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel00.jpg?raw=true\" width=\"500\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe65cd",
   "metadata": {},
   "source": [
    "## Cómputo paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d927aa",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4177d2",
   "metadata": {},
   "source": [
    "En la era moderna, el modelo convencional de cómputo serial, donde un algoritmo descompone un problema en instrucciones ejecutadas secuencialmente, ha demostrado ser ineficiente para manejar tareas complejas y voluminosas. Esto se debe a la limitación de ejecutar una sola instrucción a la vez, lo que resulta en una subutilización significativa de los recursos de hardware.\n",
    "\n",
    "El cómputo paralelo surge como una solución eficaz a este problema. Utiliza múltiples elementos de procesamiento de manera simultánea para resolver un problema, descomponiéndolo en partes que pueden ser procesadas al mismo tiempo. Esto no solo acelera el tiempo de ejecución, sino que también maximiza la utilización del hardware disponible.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel01.webp?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Imagina que tienes un gran problema que resolver y estás solo. Necesitas calcular la raíz cuadrada de ocho números diferentes. ¿A qué te dedicas? Bueno, no tienes muchas opciones. Comienzas con el primer número y calculas el resultado. Luego sigues con los demás.\n",
    "\n",
    "¿Qué pasa si tienes tres amigos buenos en matemáticas dispuestos a ayudarte? Cada uno de ellos calculará la raíz cuadrada de dos números y tu trabajo será más fácil porque la carga de trabajo se distribuye equitativamente entre tus amigos. Esto significa que su problema se resolverá más rápido.\n",
    "\n",
    "Bien, ¿está todo claro? En estos ejemplos, cada amigo representa un núcleo de la CPU. En el primer ejemplo, usted resuelve toda la tarea de forma secuencial. Esto se llama computación en serie . En el segundo ejemplo, como estás trabajando con cuatro núcleos en total, estás usando computación paralela . La computación paralela implica el uso de procesos paralelos o procesos que se dividen entre múltiples núcleos en un procesador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcb4a94",
   "metadata": {},
   "source": [
    "### Cómputo Serial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2a400e",
   "metadata": {},
   "source": [
    "Tradicionalmente, el software ha sido escrito para el cómputo serial:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel02.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "- Un problema se descompone en una serie discreta de instrucciones.\n",
    "- Las instrucciones se ejecutan secuencialmente, una tras otra.\n",
    "- Se ejecuta en un solo procesador.\n",
    "- Solo una instrucción puede ejecutarse en cualquier momento dado.\n",
    "\n",
    "por ejemplo: Ejemplo de cómputo serial en el procesamiento de nóminas.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel03.gif?raw=true\" width=\"500\" />\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13b6bea",
   "metadata": {},
   "source": [
    "### Cómputo Paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dcedba",
   "metadata": {},
   "source": [
    "En el sentido más simple, el cómputo paralelo es el uso simultáneo de múltiples recursos computacionales para resolver un problema computacional:\n",
    "\n",
    "- Un problema se divide en partes discretas que pueden resolverse de manera concurrente.\n",
    "- Cada parte se desglosa aún más en una serie de instrucciones.\n",
    "- Las instrucciones de cada parte se ejecutan simultáneamente en diferentes procesadores.\n",
    "- Se emplea un mecanismo general de control y coordinación.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel04.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Por ejemplo: Ejemplo de cómputo paralelo en el procesamiento de nóminas.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel05.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "El problema computacional debería poder:\n",
    "- Descomponerse en piezas discretas de trabajo que puedan resolverse simultáneamente;\n",
    "- Ejecutar múltiples instrucciones del programa en cualquier momento;\n",
    "- Resolverse en menos tiempo con múltiples recursos computacionales que con un solo recurso computacional.\n",
    "\n",
    "Los recursos computacionales son típicamente:\n",
    "- Una única computadora con múltiples procesadores/núcleos (su computador personal).\n",
    "- Un número arbitrario de dichas computadoras conectadas por una red (computadores de una sala de cómputo, de una oficina, o un esquema tipo [Beowulf](https://en.wikipedia.org/wiki/Beowulf_cluster)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfd8563",
   "metadata": {},
   "source": [
    "### Computadoras Paralelas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e521b367",
   "metadata": {},
   "source": [
    "Prácticamente todas las computadoras independientes actuales son paralelas desde una perspectiva de hardware:\n",
    "- Múltiples unidades funcionales (caché L1, caché L2, ramificación, precarga, decodificación, procesamiento de punto flotante, procesamiento gráfico (GPU), entero, etc.)\n",
    "- Múltiples unidades de ejecución/núcleos\n",
    "- Múltiples hilos de hardware\n",
    "Las redes conectan múltiples computadoras independientes (nodos) para formar clústeres de computadoras paralelas más grandes.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel07.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "Por ejemplo, el gráfico a continuación muestra un clúster típico de computadoras paralelas:\n",
    "- Cada nodo de cómputo es en sí mismo una computadora paralela de múltiples procesadores\n",
    "- Múltiples nodos de cómputo están interconectados con una red Infiniband\n",
    "- Nodos de propósito especial, también de múltiples procesadores, se utilizan para otros fines\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel08.gif?raw=true\" width=\"500\" />\n",
    "</p>\n",
    "\n",
    "La mayoría de las grandes computadoras paralelas del mundo (supercomputadoras) son clústeres de hardware producidos por un puñado de proveedores (en su mayoría) bien conocidos. [Top500.org](https://www.top500.org/statistics/list/)\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel09.PNG?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel10.PNG?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8284cfdf",
   "metadata": {},
   "source": [
    "## Conceptos y Terminología"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98899dae",
   "metadata": {},
   "source": [
    "### Arquitectura de Computadoras von Neumann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74f4958",
   "metadata": {},
   "source": [
    "- Nombrada en honor al matemático húngaro [John von Neumann](https://en.wikipedia.org/wiki/John_von_Neumann), quien fue el primero en formular los requisitos generales para una computadora electrónica en sus trabajos de 1945.\n",
    "- También conocida como \"computadora de programa almacenado\" - tanto las instrucciones del programa como los datos se mantienen en memoria electrónica. Difiere de las computadoras anteriores que se programaban mediante \"cableado fijo\".\n",
    "- Desde entonces, prácticamente todas las computadoras han seguido este diseño básico:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel11.gif?raw=true\" width=\"150\" />\n",
    "</p>\n",
    "\n",
    "- Compuesta de cuatro componentes principales:\n",
    "    - Memoria\n",
    "    - Unidad de Control\n",
    "    - Unidad de Lógica Aritmética\n",
    "    - Entrada/Salida\n",
    "- Se utiliza memoria de acceso aleatorio de lectura/escritura para almacenar tanto las instrucciones del programa como los datos.\n",
    "- Las instrucciones del programa son datos codificados que le indican a la computadora qué hacer.\n",
    "- Los datos son simplemente información que será utilizada por el programa.\n",
    "- La unidad de control recupera instrucciones/datos de la memoria, decodifica las instrucciones y luego coordina secuencialmente las operaciones para realizar la tarea programada.\n",
    "- La Unidad Aritmética realiza operaciones aritméticas básicas.\n",
    "- Entrada/Salida es la interfaz con el operador humano.\n",
    "Las computadoras paralelas aún siguen este diseño básico, solo que multiplicado en unidades. La arquitectura básica y fundamental permanece igual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9ee77",
   "metadata": {},
   "source": [
    "### Taxonomía Clásica de Flynn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a9f1c",
   "metadata": {},
   "source": [
    "Existen numerosas formas de clasificar las computadoras paralelas. Ejemplos de estas están disponibles en las referencias.\n",
    "Una de las clasificaciones más utilizadas, vigente desde 1966, es la llamada Taxonomía de Flynn.\n",
    "La taxonomía de Flynn distingue las arquitecturas de computadoras multiprocesador según cómo se pueden clasificar a lo largo de las dos dimensiones independientes de Flujo de Instrucciones y Flujo de Datos. Cada una de estas dimensiones puede tener solo uno de dos estados posibles: Único o Múltiple.\n",
    "La matriz a continuación define las 4 posibles clasificaciones según Flynn:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel12.gif?raw=true\" width=\"250\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe109b",
   "metadata": {},
   "source": [
    "#### Instrucción Única, Dato Único (SISD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6816793",
   "metadata": {},
   "source": [
    "- Una computadora serial (no paralela)\n",
    "- Instrucción Única: Solo un flujo de instrucciones es procesado por la CPU durante cada ciclo de reloj.\n",
    "- Dato Único: Solo un flujo de datos se utiliza como entrada durante cada ciclo de reloj.\n",
    "- Ejecución determinista.\n",
    "- Este es el tipo más antiguo de computadora.\n",
    "- Ejemplos: mainframes de generaciones anteriores, minicomputadoras, estaciones de trabajo y PCs con un único procesador/núcleo.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel13.gif?raw=true\" width=\"250\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel14.gif?raw=true\" width=\"100\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel15.PNG?raw=true\" width=\"750\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ff196",
   "metadata": {},
   "source": [
    "#### Instrucción Única, Datos Múltiples (Single Instruction, Multiple Data, SIMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfacb57",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- ***Instrucción Única:*** Todas las unidades de procesamiento ejecutan la misma instrucción en cualquier ciclo de reloj dado.  \n",
    "- ***Datos Múltiples:*** Cada unidad de procesamiento puede operar sobre un elemento de datos diferente.  \n",
    "- Mejor adecuado para problemas especializados caracterizados por un alto grado de regularidad, como el procesamiento de gráficos/imagen.  \n",
    "- Ejecución sincrónica (en paso bloqueado) y determinista.  \n",
    "- ***Dos variedades:*** Arreglos de Procesadores y Tubos de Vector.  \n",
    "\n",
    "***Ejemplos:***\n",
    "- ***Arreglos de Procesadores:*** Thinking Machines CM-2, MasPar MP-1 & MP-2, ILLIAC IV.\n",
    "- ***Canales de Vectores:*** IBM 9000, Cray X-MP, Y-MP & C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10.\n",
    "La mayoría de las computadoras modernas, especialmente aquellas con unidades de procesamiento gráfico (GPUs), emplean instrucciones y unidades de ejecución SIMD.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel16.PNG?raw=true\" width=\"750\" />\n",
    "</p>\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel17.PNG?raw=true\" width=\"750\" />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25694e28",
   "metadata": {},
   "source": [
    "#### Instrucción Múltiple, Dato Único (Multiple Instruction, Single Data, MISD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8915bfcd",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- ***Instrucción Múltiple:*** Cada unidad de procesamiento opera sobre los datos de manera independiente mediante flujos de instrucciones separados.\n",
    "- ***Dato Único:*** Un único flujo de datos se introduce en múltiples unidades de procesamiento.\n",
    "- Pocos (si acaso alguno) ejemplos reales de esta clase de computadora paralela han existido.\n",
    "- Algunos usos concebibles podrían ser:\n",
    "  - múltiples filtros de frecuencia operando sobre un único flujo de señal\n",
    "  - múltiples algoritmos de criptografía intentando descifrar un único mensaje codificado.\n",
    "  \n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel18.PNG?raw=true\" width=\"750\" />\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091703bf",
   "metadata": {},
   "source": [
    "#### Instrucción Múltiple, Datos Múltiples (Multiple Instruction, Multiple Data, MIMD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3d6a3f",
   "metadata": {},
   "source": [
    "- Un tipo de computadora paralela\n",
    "- Instrucción Múltiple: Cada procesador puede estar ejecutando un flujo de instrucciones diferente.\n",
    "- Datos Múltiples: Cada procesador puede estar trabajando con un flujo de datos diferente.\n",
    "- La ejecución puede ser sincrónica o asincrónica, determinista o no determinista.\n",
    "- Actualmente, es el tipo más común de computadora paralela; la mayoría de las supercomputadoras modernas entran en esta categoría.\n",
    "\n",
    "- ***Ejemplos:*** la mayoría de las supercomputadoras actuales, clústeres de computadoras paralelas en red y \"grids\", computadoras SMP (Symmetric Multi-Processing) de múltiples procesadores, PCs de múltiples núcleos.\n",
    "\n",
    "***Nota:*** Muchas arquitecturas MIMD también incluyen subcomponentes de ejecución SIMD.\n",
    "\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel19.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel20.PNG?raw=true\" width=\"750\" />\n",
    "</p>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be90c4",
   "metadata": {},
   "source": [
    "### Terminología General de Cómputo Paralelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7256ffc5",
   "metadata": {},
   "source": [
    "Como todo lo demás, el cómputo paralelo tiene su propio argot. A continuación, se enumeran algunos de los términos más comúnmente asociados con el cómputo paralelo. La mayoría de estos serán discutidos con más detalle más adelante.\n",
    "\n",
    "- **CPU:** Las CPU contemporáneas consisten en uno o más núcleos: una unidad de ejecución distinta con su propio flujo de instrucciones. Los núcleos dentro de una CPU pueden estar organizados en uno o más sockets, cada uno con su propia memoria distinta. Cuando una CPU consta de dos o más sockets, usualmente la infraestructura de hardware soporta el compartir memoria a través de los sockets.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Nodo:** Un \"computador en una caja\" autónomo. Usualmente compuesto por múltiples CPU/procesadores/núcleos, memoria, interfaces de red, etc. Los nodos están interconectados para formar una supercomputadora.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Tarea:** Una sección de trabajo computacional lógicamente discreta. Una tarea es típicamente un programa o un conjunto de instrucciones tipo programa que es ejecutado por un procesador. Un programa paralelo consta de múltiples tareas corriendo en múltiples procesadores.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Tubería de Procesamiento (Pipelining):** División de una tarea en pasos realizados por diferentes unidades procesadoras, con entradas fluyendo a través, muy parecido a una línea de montaje; un tipo de cómputo paralelo.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Memoria Compartida:** Describe una arquitectura de computadora donde todos los procesadores tienen acceso directo a una memoria física común. En un sentido de programación, describe un modelo donde las tareas paralelas tienen la misma \"imagen\" de memoria y pueden direccionar y acceder directamente a las mismas ubicaciones de memoria lógica, independientemente de donde la memoria física exista realmente.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- *Procesador Simétrico Múltiple (SMP):** Arquitectura de hardware de memoria compartida donde múltiples procesadores comparten un único espacio de direcciones y tienen igual acceso a todos los recursos: memoria, disco, etc.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Memoria Distribuida:** En hardware, se refiere al acceso a memoria basado en red para memoria física que no es común. Como modelo de programación, las tareas solo pueden \"ver\" lógicamente la memoria local de la máquina y deben usar comunicaciones para acceder a la memoria en otras máquinas donde otras tareas están ejecutando.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Comunicaciones:** Las tareas paralelas típicamente necesitan intercambiar datos. Esto puede lograrse de varias maneras, como a través de un bus de memoria compartido o sobre una red.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Sincronización:** La coordinación de tareas paralelas en tiempo real, muy a menudo asociada con comunicaciones. La sincronización usualmente implica la espera por parte de al menos una tarea, y por lo tanto puede causar un aumento en el tiempo de ejecución en reloj de una aplicación paralela.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Granularidad Computacional:** En cómputo paralelo, la granularidad es una medida cuantitativa o cualitativa de la relación de cálculo a comunicación.\n",
    "\n",
    "  - **Gruesa:** cantidades relativamente grandes de trabajo computacional se realizan entre eventos de comunicación.\n",
    "  - **Fina:** cantidades relativamente pequeñas de trabajo computacional se realizan entre eventos de comunicación.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Aceleración Observada (speedup):** Es uno de los indicadores más simples y ampliamente usados para el rendimiento de un programa paralelo. Determina la aceleración observada de un código que ha sido paralelizado, definida como:\n",
    "\n",
    "$$\\frac{\\text{tiempo de ejecución en serie}}{\\text{tiempo de ejecución paralelo}}$$\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Sobrecarga Paralela:** Tiempo de ejecución requerido que es único para tareas paralelas, en contraposición al que se hace para trabajo útil. La sobrecarga paralela puede incluir factores como:\n",
    "\n",
    "  - Tiempo de inicio de tarea\n",
    "  - Sincronizaciones\n",
    "  - Comunicaciones de datos\n",
    "  - Sobrecarga de software impuesta por lenguajes paralelos, bibliotecas, sistema operativo, etc.\n",
    "  - Tiempo de terminación de tarea\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Masivamente Paralelo:** Se refiere al hardware que comprende un sistema paralelo dado: tener muchos elementos de procesamiento. El significado de \"muchos\" sigue aumentando, pero actualmente, las computadoras paralelas más grandes están compuestas por elementos de procesamiento que se cuentan por cientos de miles hasta millones.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Paralelo Embarazosamente (Idealmente):** Resolver muchas tareas similares, pero independientes, simultáneamente; poca o ninguna necesidad de coordinación entre las tareas.\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- **Escalabilidad:** Se refiere a la capacidad de un sistema paralelo (hardware y/o software) para demostrar un aumento proporcional en la aceleración paralela con la adición de más recursos. Factores que contribuyen a la escalabilidad incluyen:\n",
    "\n",
    "  - Hardware: particularmente anchos de banda de memoria-CPU y propiedades de comunicación de red.\n",
    "  - Algoritmo de aplicación.\n",
    "  - Relacionados con la sobrecarga paralela.\n",
    "  - Características de su aplicación específica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f2a814",
   "metadata": {},
   "source": [
    "### Beneficios Potenciales, Límites y Costos de la Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c750fd",
   "metadata": {},
   "source": [
    "#### Ley de Amdahl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8af6757",
   "metadata": {},
   "source": [
    "La [Ley de Amdahl](https://en.wikipedia.org/wiki/Amdahl%27s_law) establece que la aceleración potencial del programa está definida por la fracción de código ($P$) que puede ser paralelizado:\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel21.PNG?raw=true\" width=\"500\" />\n",
    "</p>  \n",
    "\n",
    "$$\\text{speedup}=\\frac{1}{1-P}$$\n",
    "\n",
    "- Si ninguna parte del código puede ser paralelizado, $P = 0$ y el $speedup = 1$ (sin aceleración).\n",
    "- Si todo el código es paralelizado, $P = 1$ y el speedup (aceleración) es infinito (en teoría).\n",
    "- Si el $50\\%$ del código puede ser paralelizado, $speedup_{max}=2$, lo que significa que el código se ejecutará dos veces más rápido.\n",
    "\n",
    "Introduciendo el número de procesadores que realizan la fracción paralela del trabajo, la relación se puede modelar por:\n",
    "\n",
    "$$\\text{speedup}=\\frac{1}{\\frac{P}{N}+S}$$\n",
    "\n",
    "donde $P$ = fracción paralela, $N$ = número de procesadores y $S$ = fracción serial.\n",
    "Pronto se hace evidente que hay límites para la escalabilidad del paralelismo. Por ejemplo:\n",
    "\n",
    "```\n",
    "                         aceleración\n",
    "              -------------------------------------\n",
    "        N     P = .50   P = .90   P = .95   P = .99\n",
    "      -----   -------   -------   -------   -------\n",
    "         10      1.82      5.26      6.89      9.17\n",
    "        100      1.98      9.17     16.80     50.25    \n",
    "      1,000      1.99      9.91     19.62     90.99\n",
    "     10,000      1.99      9.91     19.96     99.02\n",
    "    100,000      1.99      9.99     19.99     99.90\n",
    "```\n",
    "\n",
    "- ***Cita \"famosa\":*** *¡Puedes pasar una vida intentando paralelizar el 95% de tu código, y nunca lograrás más de 20 veces de aceleración sin importar cuántos procesadores utilices!* \n",
    "\n",
    "Sin embargo, ciertos problemas demuestran un aumento en el rendimiento al incrementar el tamaño del problema. Por ejemplo:\n",
    "\n",
    "```\n",
    "        Cálculos de Malla 2D\n",
    "        Fracción Paralela        85 segundos 85%   \n",
    "        Fracción Serial          15 segundos   15%   \n",
    "        \n",
    "```\n",
    "\n",
    "Podemos aumentar el tamaño del problema duplicando las dimensiones de la malla y dividiendo a la mitad el paso de tiempo. Esto resulta en cuatro veces la cantidad de puntos de la malla y el doble de número de pasos de tiempo. Los tiempos entonces se ven así:  \n",
    "\n",
    "```\n",
    "        Cálculos de Malla 2D \n",
    "        Fracción Paralela         680 segundos 97.84%   \n",
    "        Fracción Serial           15 segundos    2.16%   \n",
    "```\n",
    "\n",
    "Problemas que aumentan el porcentaje de tiempo paralelo con su tamaño son más escalables que problemas con un porcentaje fijo de tiempo paralelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce4b2eb",
   "metadata": {},
   "source": [
    "#### Complejidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0a10a",
   "metadata": {},
   "source": [
    "En general, las aplicaciones paralelas son más complejas que las aplicaciones seriales correspondientes. No solo se tienen múltiples flujos de instrucciones ejecutándose al mismo tiempo, sino que también se tiene el flujo de datos entre ellos.\n",
    "Los costos de la complejidad se miden en tiempo de programador en prácticamente todos los aspectos del ciclo de desarrollo de software:\n",
    "- Diseño\n",
    "- Codificación\n",
    "- Depuración\n",
    "- Afinación\n",
    "- Mantenimiento  \n",
    "\n",
    "Adherirse a las \"buenas\" prácticas de desarrollo de software es esencial al desarrollar aplicaciones paralelas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e62acc",
   "metadata": {},
   "source": [
    "#### Portabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015a718",
   "metadata": {},
   "source": [
    "Gracias a la estandarización en varias APIs, como MPI, OpenMP y los hilos POSIX, los problemas de portabilidad con programas paralelos no son tan graves como en años pasados. Sin embargo,\n",
    "todos los problemas habituales de portabilidad asociados con programas seriales se aplican a programas paralelos. Por ejemplo, si se utilizan \"mejoras\" de un proveedor a Fortran, C o C++, la portabilidad será un problema.  \n",
    "\n",
    "A pesar de que existen estándares para varias APIs, las implementaciones difieren en varios detalles, a veces hasta el punto de requerir modificaciones del código para efectuar la portabilidad.  \n",
    "\n",
    "Los sistemas operativos pueden jugar un papel clave en los problemas de portabilidad del código.\n",
    "Las arquitecturas de hardware son característicamente muy variables y pueden afectar la portabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d13ff4",
   "metadata": {},
   "source": [
    "#### Requisitos de Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86929ab",
   "metadata": {},
   "source": [
    "La intención principal de la programación paralela es disminuir el tiempo de ejecución en reloj de pared, sin embargo, para lograr esto, se requiere más tiempo de CPU. Por ejemplo, un código paralelo que se ejecuta en 1 hora en 8 procesadores en realidad utiliza 8 horas de tiempo de CPU.  \n",
    "\n",
    "La cantidad de memoria requerida puede ser mayor para códigos paralelos que para códigos seriales, debido a la necesidad de replicar datos y por los sobrecargos asociados con bibliotecas de soporte paralelo y subsistemas.  \n",
    "\n",
    "Para programas paralelos de corta duración, en realidad puede haber una disminución en el rendimiento en comparación con una implementación serial similar. Los costos de sobrecarga asociados con la configuración del entorno paralelo, la creación de tareas, las comunicaciones y la terminación de tareas pueden constituir una parte significativa del tiempo total de ejecución para ejecuciones cortas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6619a827",
   "metadata": {},
   "source": [
    "#### Escalabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1102d3c1",
   "metadata": {},
   "source": [
    "Dos tipos de escalabilidad basados en el tiempo hasta la solución: escalabilidad fuerte y escalabilidad débil.  \n",
    "\n",
    "- ***Escalabilidad Fuerte (Amdahl):***\n",
    "  - El tamaño total del problema permanece fijo a medida que se agregan más procesadores.\n",
    "  - El objetivo es ejecutar el mismo tamaño de problema más rápido.\n",
    "  - La escalabilidad perfecta significa que el problema se resuelve en tiempo $1/P$ (en comparación con serial).  \n",
    "<p>&nbsp;</p>\n",
    "\n",
    "- ***Escalabilidad Débil (Gustafson):***\n",
    "  - El tamaño del problema por procesador se mantiene fijo a medida que se agregan más procesadores. El tamaño total del problema es proporcional al número de procesadores utilizados.\n",
    "  - El objetivo es ejecutar un problema más grande en la misma cantidad de tiempo.\n",
    "  - La escalabilidad perfecta significa que el problema $Px$ se ejecuta en el mismo tiempo que una ejecución de un solo procesador.  \n",
    "\n",
    "La capacidad de rendimiento de un programa paralelo para escalar es el resultado de una serie de factores interrelacionados. Simplemente agregar más procesadores rara vez es la respuesta.  \n",
    "\n",
    "El algoritmo puede tener límites inherentes a la escalabilidad. En algún punto, agregar más recursos causa una disminución en el rendimiento. Esta es una situación común con muchas aplicaciones paralelas.  \n",
    "\n",
    "Los factores de hardware juegan un papel significativo en la escalabilidad. Ejemplos:\n",
    "- Ancho de banda del bus memoria-CPU en una máquina SMP\n",
    "- Ancho de banda de la red de comunicaciones\n",
    "- Cantidad de memoria disponible en una máquina dada o un conjunto de máquinas\n",
    "- Velocidad del reloj del procesador  \n",
    "\n",
    "Las bibliotecas de soporte paralelo y el software de subsistemas pueden limitar la escalabilidad independientemente de su aplicación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788bf420",
   "metadata": {},
   "source": [
    "## Arquitecturas de Memoria en Computadoras Paralelas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b1870",
   "metadata": {},
   "source": [
    "### Memoria Compartida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8055d35",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04507da4",
   "metadata": {},
   "source": [
    "- Las computadoras paralelas con memoria compartida varían ampliamente, pero generalmente tienen en común la capacidad de todos los procesadores para acceder a toda la memoria como un espacio de direcciones global.  \n",
    "\n",
    "- Varios procesadores pueden operar de manera independiente pero comparten los mismos recursos de memoria.  \n",
    "\n",
    "- Los cambios en una ubicación de memoria realizados por un procesador son visibles para todos los demás procesadores.  \n",
    "- Históricamente, las máquinas de memoria compartida han sido clasificadas como UMA y NUMA, basándose en los tiempos de acceso a la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76699d43",
   "metadata": {},
   "source": [
    "#### Acceso Uniforme a la Memoria (Uniform Memory Access , UMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd46707",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel22.gif?raw=true\" width=\"300\" />\n",
    "</p>  \n",
    "\n",
    "- Hoy en día, comúnmente representado por máquinas Multiprocesador Simétrico (SMP)  \n",
    "- Procesadores idénticos  \n",
    "- Acceso igual y tiempos de acceso a la memoria  \n",
    "- A veces llamado CC-UMA - UMA Coherente en Caché. Coherente en caché significa que si un procesador actualiza una ubicación en la memoria compartida, todos los demás procesadores conocen la actualización. La coherencia de caché se logra a nivel de hardware.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9d77db",
   "metadata": {},
   "source": [
    "#### Acceso No Uniforme a la Memoria (Non-Uniform Memory Access, NUMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04c608d",
   "metadata": {},
   "source": [
    "- A menudo se realiza mediante la conexión física de dos o más SMP (Multiprocesadores Simétricos).\n",
    "- Un SMP puede acceder directamente a la memoria de otro SMP.\n",
    "- No todos los procesadores tienen el mismo tiempo de acceso a todas las memorias.\n",
    "- El acceso a la memoria a través del enlace es más lento.\n",
    "- Si se mantiene la coherencia de caché, entonces también puede llamarse CC-NUMA - NUMA Coherente en Caché.\n",
    "\n",
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel23.gif?raw=true\" width=\"350\" />\n",
    "</p>  \n",
    "\n",
    "**Ventajas**\n",
    "- El espacio de direcciones global proporciona una perspectiva de programación amigable para el usuario hacia la memoria.\n",
    "- El intercambio de datos entre tareas es rápido y uniforme debido a la proximidad de la memoria a las CPU.\n",
    "\n",
    "**Desventajas**\n",
    "- La principal desventaja es la falta de escalabilidad entre la memoria y las CPU. Agregar más CPU puede aumentar geométricamente el tráfico en el camino compartido memoria-CPU y, para sistemas coherentes en caché, aumentar geométricamente el tráfico asociado con la gestión de caché/memoria.\n",
    "- Responsabilidad del programador por construcciones de sincronización que aseguren el acceso \"correcto\" de la memoria global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c7f7da",
   "metadata": {},
   "source": [
    "### Memoria Distribuida (Distributed Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0987f",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a920c",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel24.gif?raw=true\" width=\"350\" />\n",
    "</p>  \n",
    "\n",
    "Al igual que los sistemas de memoria compartida, los sistemas de memoria distribuida varían ampliamente, pero comparten una característica común. Los sistemas de memoria distribuida requieren una red de comunicación para conectar la memoria entre procesadores.\n",
    "\n",
    "Los procesadores tienen su propia memoria local. Las direcciones de memoria en un procesador no se mapean a otro procesador, por lo que no existe un concepto de espacio de direcciones global en todos los procesadores.\n",
    "\n",
    "Debido a que cada procesador tiene su propia memoria local, opera de manera independiente. Los cambios que realiza en su memoria local no tienen efecto en la memoria de otros procesadores. Por lo tanto, el concepto de coherencia de caché no se aplica.\n",
    "\n",
    "Cuando un procesador necesita acceder a datos en otro procesador, generalmente es tarea del programador definir explícitamente cómo y cuándo se comunican los datos. La sincronización entre tareas también es responsabilidad del programador.\n",
    "\n",
    "La \"tela\" de red utilizada para la transferencia de datos varía ampliamente, aunque puede ser tan simple como Ethernet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704955fb",
   "metadata": {},
   "source": [
    "#### Ventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ec5dd",
   "metadata": {},
   "source": [
    "- La memoria es escalable con el número de procesadores. Aumente el número de procesadores y el tamaño de la memoria aumenta proporcionalmente.  \n",
    "- Cada procesador puede acceder rápidamente a su propia memoria sin interferencias y sin los costos generados al tratar de mantener la coherencia global de la caché.  \n",
    "- Efectividad en costos: puede usar procesadores y redes comerciales disponibles en el mercado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1845ef10",
   "metadata": {},
   "source": [
    "#### Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707304c6",
   "metadata": {},
   "source": [
    "- El programador es responsable de muchos detalles asociados con la comunicación de datos entre procesadores.  \n",
    "\n",
    "- Puede ser difícil mapear estructuras de datos existentes, basadas en memoria global, a esta organización de memoria.  \n",
    "\n",
    "- Tiempos de acceso a la memoria no uniformes: los datos que residen en un nodo remoto tardan más en accederse que los datos locales al nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c051a836",
   "metadata": {},
   "source": [
    "### Memoria Híbrida Distribuida-Compartida (Hybrid Distributed-Shared Memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7772d6c",
   "metadata": {},
   "source": [
    "#### Características Generales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9330f5e",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel25.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "- Las computadoras más grandes y rápidas del mundo hoy en día emplean tanto arquitecturas de memoria compartida como distribuida.  \n",
    "\n",
    "- El componente de memoria compartida puede ser una máquina de memoria compartida y/o unidades de procesamiento gráfico (GPU).  \n",
    "\n",
    "- El componente de memoria distribuida es la interconexión de múltiples máquinas de memoria compartida/GPU, que solo conocen su propia memoria, no la memoria en otra máquina. Por lo tanto, se requieren comunicaciones de red para mover datos de una máquina a otra.  \n",
    "\n",
    "- Las tendencias actuales parecen indicar que este tipo de arquitectura de memoria continuará predominando y aumentando en el ámbito de la computación de alto rendimiento en el futuro previsible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92165811",
   "metadata": {},
   "source": [
    "#### Ventajas y Desventajas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b53ea",
   "metadata": {},
   "source": [
    "Lo que es común tanto a las arquitecturas de memoria compartida como distribuida.\n",
    "\n",
    "- **Ventajas:**\n",
    "  - **Escalabilidad aumentada:** Un aspecto importante de la memoria híbrida es la capacidad de escalar más eficientemente al combinar los beneficios de ambas arquitecturas, permitiendo manejar eficazmente grandes volúmenes de datos y procesamiento intensivo.\n",
    "<p>&nbsp;</p>\n",
    "  \n",
    "- **Desventajas:**\n",
    "  - **Complejidad aumentada para el programador:** La necesidad de gestionar dos tipos diferentes de arquitecturas de memoria puede complicar significativamente el diseño y la implementación del software. Los programadores deben ser conscientes de dónde y cómo se almacenan los datos, además de manejar la comunicación entre diferentes unidades de memoria.\n",
    "\n",
    "Este enfoque híbrido ofrece un equilibrio entre el acceso rápido a memoria local en las máquinas individuales y la capacidad de trabajar en conjunto en tareas más grandes que requieren datos de múltiples fuentes, aprovechando así las fortalezas de ambos tipos de memoria para mejorar el rendimiento general y la eficiencia del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e6135",
   "metadata": {},
   "source": [
    "## Modelos de Programación Paralela"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24cd38",
   "metadata": {},
   "source": [
    "### Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c9dc4",
   "metadata": {},
   "source": [
    "Existen varios modelos de programación paralela de uso común:\n",
    "\n",
    "- Memoria Compartida (sin hilos, threads)\n",
    "- Hilos\n",
    "- Memoria Distribuida / Paso de Mensajes\n",
    "- Paralelismo de Datos\n",
    "- Híbrido\n",
    "- Programa Único Múltiples Datos (SPMD)\n",
    "- Múltiples Programas Múltiples Datos (MPMD)\n",
    "\n",
    "Los modelos de programación paralela existen como una abstracción por encima de las arquitecturas de hardware y memoria. Aunque puede no parecer evidente, estos modelos NO son específicos de un tipo particular de máquina o arquitectura de memoria. De hecho, cualquiera de estos modelos puede (teóricamente) implementarse en cualquier hardware subyacente. A continuación, se discuten dos ejemplos del pasado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5433a",
   "metadata": {},
   "source": [
    "### Modelo de memoria compartida en una máquina de memoria distribuida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7437bce",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel26.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "Enfoque *ALLCACHE de Kendall Square Research* (*KSR*). La memoria de la máquina estaba físicamente distribuida a través de máquinas en red, pero aparecía para el usuario como un espacio de direcciones de memoria compartida global. Genéricamente, este enfoque se conoce como \"memoria compartida virtual\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ab55a",
   "metadata": {},
   "source": [
    "### Modelo de memoria distribuida en una máquina de memoria compartida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a91d3",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel27.PNG?raw=true\" width=\"750\" />\n",
    "</p>  \n",
    "\n",
    "[Interface de Paso de Mensajes](https://en.wikipedia.org/wiki/Message_Passing_Interface) (Message Passing Interface, MPI) en SGI Origin 2000. El SGI Origin 2000 empleaba el tipo de arquitectura de memoria compartida CC-NUMA, donde cada tarea tiene acceso directo al espacio de direcciones global distribuido en todas las máquinas. Sin embargo, la capacidad de enviar y recibir mensajes usando MPI, como se hace comúnmente en una red de máquinas de memoria distribuida, fue implementada y comúnmente utilizada.\n",
    "\n",
    "¿Qué modelo usar? Esto es a menudo una combinación de lo que está disponible y elección personal. No hay un modelo \"mejor\", aunque ciertamente hay implementaciones mejores de algunos modelos sobre otros.\n",
    "\n",
    "Las siguientes secciones describen cada uno de los modelos mencionados anteriormente y también discuten algunas de sus implementaciones reales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07372f2",
   "metadata": {},
   "source": [
    "### Modelo de Memoria Compartida (sin hilos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579a3c67",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel28.gif?raw=true\" width=\"200\" />\n",
    "</p>  \n",
    "\n",
    "En este modelo de programación, los procesos o tareas comparten un espacio de direcciones común, al cual leen y escriben de manera asincrónica.  \n",
    "\n",
    "Se utilizan varios mecanismos como cerrojos y semáforos para controlar el acceso a la memoria compartida, resolver contiendas y prevenir condiciones de carrera y bloqueos mutuos (deadlocks).\n",
    "Este es quizás el modelo de programación paralela más simple.\n",
    "\n",
    "Una ventaja de este modelo desde el punto de vista del programador es que la noción de \"propiedad\" de datos no existe, por lo que no es necesario especificar explícitamente la comunicación de datos entre tareas. Todos los procesos ven y tienen igual acceso a la memoria compartida. El desarrollo del programa a menudo puede ser simplificado.\n",
    "\n",
    "Una desventaja importante en términos de rendimiento es que se vuelve más difícil entender y gestionar la localidad de los datos:\n",
    "- Mantener los datos locales al proceso que trabaja en ellos conserva los accesos a la memoria, las actualizaciones de caché y el tráfico del bus que ocurre cuando múltiples procesos usan los mismos datos.\n",
    "- Desafortunadamente, controlar la localidad de los datos es difícil de entender y puede estar más allá del control del usuario promedio.\n",
    "\n",
    "***Implementaciones***\n",
    "\n",
    "- En máquinas de memoria compartida independientes, los sistemas operativos nativos, compiladores y/o hardware proporcionan soporte para la programación de memoria compartida. Por ejemplo, el estándar POSIX proporciona una API para usar memoria compartida, y UNIX ofrece segmentos de memoria compartida (shmget, shmat, shmctl, etc.).  \n",
    "\n",
    "- En máquinas de memoria distribuida, la memoria está físicamente distribuida a través de una red de máquinas, pero se hace global a través de hardware y software especializado. Hay disponibles varias implementaciones de [SHMEM](http://en.wikipedia.org/wiki/SHMEM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b03980d",
   "metadata": {},
   "source": [
    "### El modelo de hilos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38e0419",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/EstructuraDatosAlgoritmos2/blob/main/images/Parallel29.PNG?raw=true\" width=\"200\" />\n",
    "</p>  \n",
    "\n",
    "Este modelo de programación es un tipo de programación de memoria compartida.\n",
    "\n",
    "En el modelo de hilos de programación paralela, un único proceso \"pesado\" puede tener múltiples rutas de ejecución \"ligeras\" y concurrentes.\n",
    "\n",
    "Por ejemplo:\n",
    "- El programa principal `a.out` es programado para ejecutarse por el sistema operativo nativo. `a.out` carga y adquiere todos los recursos necesarios del sistema y del usuario para ejecutarse. Este es el proceso \"pesado\".  \n",
    "\n",
    "- `a.out` realiza algún trabajo serial, y luego crea una serie de tareas (hilos) que pueden ser programadas y ejecutadas de forma concurrente por el sistema operativo.  \n",
    "\n",
    "- Cada hilo tiene datos locales, pero también comparte todos los recursos de `a.out`. Esto ahorra la sobrecarga asociada con replicar los recursos de un programa para cada hilo (\"ligero\"). Cada hilo también se beneficia de una vista global de la memoria porque comparte el espacio de memoria de `a.out`.  \n",
    "\n",
    "- El trabajo de un hilo puede describirse mejor como una subrutina dentro del programa principal. Cualquier hilo puede ejecutar cualquier subrutina al mismo tiempo que otros hilos.  \n",
    "\n",
    "- Los hilos se comunican entre sí a través de la memoria global (actualizando ubicaciones de direcciones). Esto requiere constructos de sincronización para asegurar que más de un hilo no esté actualizando la misma dirección global al mismo tiempo.  \n",
    "\n",
    "- Los hilos pueden aparecer y desaparecer, pero `a.out` permanece presente para proporcionar los recursos compartidos necesarios hasta que la aplicación se haya completado.\n",
    "\n",
    "***Implementaciones***\n",
    "\n",
    "Desde una perspectiva de programación, las implementaciones de hilos comúnmente comprenden:  \n",
    "\n",
    "- Una biblioteca de subrutinas que se llaman desde dentro del código fuente paralelo.  \n",
    "\n",
    "- Un conjunto de directivas de compilador incrustadas en el código fuente serial o paralelo.  \n",
    "\n",
    "En ambos casos, el programador es responsable de determinar el paralelismo (aunque los compiladores a veces pueden ayudar).\n",
    "\n",
    "- Las implementaciones con hilos no son nuevas en la computación. Históricamente, los vendedores de hardware han implementado sus propias versiones propietarias de hilos. Estas implementaciones diferían sustancialmente entre sí, lo que dificultaba a los programadores desarrollar aplicaciones con hilos portátiles.  \n",
    "\n",
    "- Los esfuerzos de estandarización no relacionados han resultado en dos implementaciones muy diferentes de hilos: [Hilos POSIX](https://en.wikipedia.org/wiki/Pthreads) y [OpenMP](https://en.wikipedia.org/wiki/OpenMP)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e16a07",
   "metadata": {},
   "source": [
    "***Hilos POSIX (Pthreads):*** \n",
    "\n",
    "Esta es una opción poderosa para los programadores que necesitan control completo sobre la ejecución del paralelismo. Los Pthreads permiten una gran flexibilidad y control en la gestión de hilos, sincronización, y el manejo de recursos compartidos. Son ampliamente utilizados en entornos donde se necesita un ajuste fino del rendimiento y la gestión de la concurrencia.  \n",
    "\n",
    "- Especificados por el estándar IEEE POSIX 1003.1c (1995). Solo para el lenguaje C.\n",
    "- Parte de los sistemas operativos Unix/Linux\n",
    "- Basado en bibliotecas\n",
    "- Comúnmente referido como Pthreads.\n",
    "- Paralelismo muy explícito; requiere una atención significativa al detalle por parte del programador."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a45c5f",
   "metadata": {},
   "source": [
    "***OpenMP:*** \n",
    "\n",
    "Este modelo es altamente valorado por su simplicidad y eficacia, especialmente para aquellos que están comenzando con la programación paralela o aquellos que necesitan implementar paralelismo en programas existentes con el mínimo esfuerzo. OpenMP utiliza directivas de compilador para automatizar la creación de hilos, la distribución de tareas y la sincronización, lo que facilita enormemente la tarea del programador. Además, debido a que OpenMP es soportado por muchos compiladores, garantiza un buen nivel de portabilidad entre diferentes plataformas. \n",
    "\n",
    "- Estándar de la industria, definido y respaldado conjuntamente por un grupo de importantes proveedores de hardware y software de computadoras, organizaciones e individuos.\n",
    "- Basado en directivas de compilador\n",
    "- Portátil / multiplataforma, incluyendo plataformas Unix y Windows\n",
    "- Disponible en implementaciones de C/C++ y Fortran\n",
    "- Puede ser muy fácil y simple de usar - proporciona un \"paralelismo incremental\". Puede comenzar con código serial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0064a",
   "metadata": {},
   "source": [
    "Para más información y profundizar en los detalles de cada modelo de programación con hilos, aquí tienes recursos útiles:\n",
    "\n",
    "1. **Tutorial de Hilos POSIX**: Puedes encontrar un tutorial completo sobre Hilos POSIX en el sitio web del Laboratorio Nacional Lawrence Livermore (LLNL) accediendo al documento directamente a través de [este enlace a hpc.llnl.gov](https://hpc.llnl.gov/sites/default/files/2019.08.21.TAU_.pdf). Este tutorial proporcionará una guía detallada sobre cómo implementar y manejar hilos POSIX en tus proyectos de programación.\n",
    "\n",
    "2. **Tutorial de OpenMP**: Para aprender más sobre OpenMP, el Laboratorio Nacional Lawrence Livermore ofrece un tutorial completo que puedes explorar. Visita [la página de tutoriales de OpenMP del LLNL](https://hpc-tutorials.llnl.gov/openmp/) para obtener información práctica y ejemplos de cómo utilizar OpenMP en aplicaciones paralelas, tanto en C/C++ como en Fortran.\n",
    "\n",
    "Estos recursos son excelentes puntos de partida para desarrolladores interesados en la programación paralela, proporcionando tanto fundamentos teóricos como ejemplos prácticos que ayudan a entender mejor cómo implementar estos modelos en diversos entornos y plataformas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d31ed1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "632964f0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edff8ba3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82c9a2dd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
